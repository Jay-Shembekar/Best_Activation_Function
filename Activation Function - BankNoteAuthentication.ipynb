{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9332f1a2",
   "metadata": {},
   "source": [
    "# Selecting Best Suitable Activation Function \n",
    "<font size=\"5\">Submitted By : <a href=\"https://www.linkedin.com/in/jay-shembekar-13b223146\" >Jay Shembekar </a></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49daf574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variance  skewness  curtosis  entropy  class\n",
       "0   3.62160    8.6661   -2.8073 -0.44699      0\n",
       "1   4.54590    8.1674   -2.4586 -1.46210      0\n",
       "2   3.86600   -2.6383    1.9242  0.10645      0\n",
       "3   3.45660    9.5228   -4.0112 -3.59440      0\n",
       "4   0.32924   -4.4552    4.5718 -0.98880      0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# reading file, Dataset used - Bank Note Authentication\n",
    "df = pd.read_csv('BankNote_Authentication.csv') \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5f64df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating X and y for independent and dependent features\n",
    "\n",
    "X = df.iloc[:, 0:4]\n",
    "y = df.iloc[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c07e5e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset into train and test datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21089c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "X_train = mms.fit_transform(X_train)\n",
    "X_test = mms.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "565cf0ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.41049142, 0.8566794 , 0.30278071, 0.26001485],\n",
       "       [0.21781793, 0.62477783, 0.26520602, 0.69678059],\n",
       "       [0.45086951, 0.2196657 , 0.51981821, 0.79406437],\n",
       "       ...,\n",
       "       [0.56173284, 0.55276766, 0.1324014 , 0.77018593],\n",
       "       [0.66580916, 0.50592299, 0.45046202, 0.8658303 ],\n",
       "       [0.36501683, 0.92032464, 0.34161156, 0.28806621]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "541a7baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten, LeakyReLU, BatchNormalization, Dropout, LeakyReLU, PReLU, ELU\n",
    "from keras.activations import relu, sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fa3168",
   "metadata": {},
   "source": [
    "## Using different Activation Functions for hidden layer\n",
    "    1. relu\n",
    "    2. sigmoid\n",
    "    3. softmax\n",
    "    4. softplus\n",
    "    5. softsign\n",
    "    6. tanh\n",
    "    7. selu\n",
    "    8. exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1c5f990",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(units = 3, activation = 'relu', input_dim = 4)) \n",
    "model1.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "model1.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06ecb2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(units = 3, activation = 'sigmoid', input_dim = 4)) \n",
    "model2.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "model2.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f74fa768",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(units = 3, activation = 'softmax', input_dim = 4)) \n",
    "model3.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "model3.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f27d0598",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Dense(units = 3, activation = 'softplus', input_dim = 4)) \n",
    "model4.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "model4.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec67f4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(Dense(units = 3, activation = 'softsign', input_dim = 4)) \n",
    "model5.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "model5.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3a3e7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = Sequential()\n",
    "model6.add(Dense(units = 3, activation = 'tanh', input_dim = 4)) \n",
    "model6.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "model6.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aece7b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = Sequential()\n",
    "model7.add(Dense(units = 3, activation = 'selu', input_dim = 4)) \n",
    "model7.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "model7.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcf97c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model8 = Sequential()\n",
    "model8.add(Dense(units = 3, activation = 'exponential', input_dim = 4)) \n",
    "model8.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "model8.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c0f518c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [('relu', model1),\n",
    "          ('sigmoid', model2),\n",
    "          ('softmax', model3),\n",
    "          ('softplus', model4),\n",
    "          ('softsign', model5),\n",
    "          ('tanh', model6),\n",
    "          ('selu', model7),\n",
    "          ('exponential', model8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e33cb2c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6548 - accuracy: 0.5941 - val_loss: 0.6757 - val_accuracy: 0.5521\n",
      "Epoch 2/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6494 - accuracy: 0.6112 - val_loss: 0.6687 - val_accuracy: 0.5804\n",
      "Epoch 3/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6450 - accuracy: 0.6128 - val_loss: 0.6638 - val_accuracy: 0.5804\n",
      "Epoch 4/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6397 - accuracy: 0.6267 - val_loss: 0.6579 - val_accuracy: 0.5962\n",
      "Epoch 5/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6355 - accuracy: 0.6330 - val_loss: 0.6538 - val_accuracy: 0.5962\n",
      "Epoch 6/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6306 - accuracy: 0.6330 - val_loss: 0.6487 - val_accuracy: 0.5994\n",
      "Epoch 7/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6255 - accuracy: 0.6330 - val_loss: 0.6446 - val_accuracy: 0.5994\n",
      "Epoch 8/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6211 - accuracy: 0.6439 - val_loss: 0.6385 - val_accuracy: 0.6120\n",
      "Epoch 9/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6157 - accuracy: 0.6470 - val_loss: 0.6327 - val_accuracy: 0.6215\n",
      "Epoch 10/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6103 - accuracy: 0.6516 - val_loss: 0.6279 - val_accuracy: 0.6278\n",
      "Epoch 11/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6053 - accuracy: 0.6796 - val_loss: 0.6217 - val_accuracy: 0.6372\n",
      "Epoch 12/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5996 - accuracy: 0.6781 - val_loss: 0.6168 - val_accuracy: 0.6498\n",
      "Epoch 13/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5941 - accuracy: 0.6936 - val_loss: 0.6100 - val_accuracy: 0.6530\n",
      "Epoch 14/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5887 - accuracy: 0.6983 - val_loss: 0.6041 - val_accuracy: 0.6562\n",
      "Epoch 15/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5831 - accuracy: 0.7014 - val_loss: 0.5987 - val_accuracy: 0.6625\n",
      "Epoch 16/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5771 - accuracy: 0.7045 - val_loss: 0.5937 - val_accuracy: 0.6751\n",
      "Epoch 17/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5709 - accuracy: 0.7092 - val_loss: 0.5849 - val_accuracy: 0.6814\n",
      "Epoch 18/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5648 - accuracy: 0.7154 - val_loss: 0.5790 - val_accuracy: 0.6845\n",
      "Epoch 19/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5588 - accuracy: 0.7201 - val_loss: 0.5719 - val_accuracy: 0.7035\n",
      "Epoch 20/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5522 - accuracy: 0.7325 - val_loss: 0.5651 - val_accuracy: 0.7035\n",
      "Epoch 21/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5456 - accuracy: 0.7418 - val_loss: 0.5581 - val_accuracy: 0.7098\n",
      "Epoch 22/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5392 - accuracy: 0.7449 - val_loss: 0.5514 - val_accuracy: 0.7129\n",
      "Epoch 23/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5328 - accuracy: 0.7589 - val_loss: 0.5451 - val_accuracy: 0.7192\n",
      "Epoch 24/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5259 - accuracy: 0.7683 - val_loss: 0.5380 - val_accuracy: 0.7256\n",
      "Epoch 25/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5199 - accuracy: 0.7729 - val_loss: 0.5301 - val_accuracy: 0.7413\n",
      "Epoch 26/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5129 - accuracy: 0.7760 - val_loss: 0.5252 - val_accuracy: 0.7382\n",
      "Epoch 27/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5066 - accuracy: 0.7823 - val_loss: 0.5181 - val_accuracy: 0.7445\n",
      "Epoch 28/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5004 - accuracy: 0.7869 - val_loss: 0.5104 - val_accuracy: 0.7571\n",
      "Epoch 29/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4931 - accuracy: 0.8056 - val_loss: 0.5027 - val_accuracy: 0.7603\n",
      "Epoch 30/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4865 - accuracy: 0.8134 - val_loss: 0.4966 - val_accuracy: 0.7666\n",
      "Epoch 31/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.8134 - val_loss: 0.4906 - val_accuracy: 0.7729\n",
      "Epoch 32/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4736 - accuracy: 0.8134 - val_loss: 0.4833 - val_accuracy: 0.7760\n",
      "Epoch 33/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4666 - accuracy: 0.8196 - val_loss: 0.4767 - val_accuracy: 0.7855\n",
      "Epoch 34/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.8212 - val_loss: 0.4711 - val_accuracy: 0.7855\n",
      "Epoch 35/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4534 - accuracy: 0.8180 - val_loss: 0.4632 - val_accuracy: 0.7886\n",
      "Epoch 36/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4465 - accuracy: 0.8289 - val_loss: 0.4539 - val_accuracy: 0.8044\n",
      "Epoch 37/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4404 - accuracy: 0.8383 - val_loss: 0.4489 - val_accuracy: 0.7950\n",
      "Epoch 38/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4341 - accuracy: 0.8289 - val_loss: 0.4440 - val_accuracy: 0.7950\n",
      "Epoch 39/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.8414 - val_loss: 0.4356 - val_accuracy: 0.8233\n",
      "Epoch 40/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4205 - accuracy: 0.8398 - val_loss: 0.4298 - val_accuracy: 0.8233\n",
      "Epoch 41/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4142 - accuracy: 0.8460 - val_loss: 0.4217 - val_accuracy: 0.8328\n",
      "Epoch 42/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4095 - accuracy: 0.8398 - val_loss: 0.4150 - val_accuracy: 0.8423\n",
      "Epoch 43/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4021 - accuracy: 0.8523 - val_loss: 0.4077 - val_accuracy: 0.8580\n",
      "Epoch 44/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3953 - accuracy: 0.8523 - val_loss: 0.4038 - val_accuracy: 0.8486\n",
      "Epoch 45/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3891 - accuracy: 0.8569 - val_loss: 0.3968 - val_accuracy: 0.8612\n",
      "Epoch 46/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3830 - accuracy: 0.8585 - val_loss: 0.3889 - val_accuracy: 0.8707\n",
      "Epoch 47/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3779 - accuracy: 0.8554 - val_loss: 0.3828 - val_accuracy: 0.8738\n",
      "Epoch 48/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3722 - accuracy: 0.8631 - val_loss: 0.3776 - val_accuracy: 0.8738\n",
      "Epoch 49/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3655 - accuracy: 0.8647 - val_loss: 0.3721 - val_accuracy: 0.8770\n",
      "Epoch 50/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3598 - accuracy: 0.8694 - val_loss: 0.3667 - val_accuracy: 0.8801\n",
      "Epoch 51/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3545 - accuracy: 0.8802 - val_loss: 0.3602 - val_accuracy: 0.8896\n",
      "Epoch 52/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3487 - accuracy: 0.8756 - val_loss: 0.3539 - val_accuracy: 0.8896\n",
      "Epoch 53/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3430 - accuracy: 0.8740 - val_loss: 0.3482 - val_accuracy: 0.8927\n",
      "Epoch 54/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3380 - accuracy: 0.8896 - val_loss: 0.3440 - val_accuracy: 0.8959\n",
      "Epoch 55/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8865 - val_loss: 0.3352 - val_accuracy: 0.9022\n",
      "Epoch 56/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3271 - accuracy: 0.8974 - val_loss: 0.3346 - val_accuracy: 0.8959\n",
      "Epoch 57/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3230 - accuracy: 0.8927 - val_loss: 0.3286 - val_accuracy: 0.8991\n",
      "Epoch 58/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3172 - accuracy: 0.9036 - val_loss: 0.3206 - val_accuracy: 0.9022\n",
      "Epoch 59/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3117 - accuracy: 0.9082 - val_loss: 0.3160 - val_accuracy: 0.9022\n",
      "Epoch 60/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3071 - accuracy: 0.9082 - val_loss: 0.3104 - val_accuracy: 0.9022\n",
      "Epoch 61/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3032 - accuracy: 0.9176 - val_loss: 0.3064 - val_accuracy: 0.9022\n",
      "Epoch 62/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2976 - accuracy: 0.9129 - val_loss: 0.3006 - val_accuracy: 0.9022\n",
      "Epoch 63/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2932 - accuracy: 0.9207 - val_loss: 0.2957 - val_accuracy: 0.9054\n",
      "Epoch 64/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2882 - accuracy: 0.9285 - val_loss: 0.2904 - val_accuracy: 0.9117\n",
      "Epoch 65/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2840 - accuracy: 0.9300 - val_loss: 0.2862 - val_accuracy: 0.9117\n",
      "Epoch 66/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2792 - accuracy: 0.9300 - val_loss: 0.2806 - val_accuracy: 0.9211\n",
      "Epoch 67/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2753 - accuracy: 0.9331 - val_loss: 0.2777 - val_accuracy: 0.9180\n",
      "Epoch 68/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2713 - accuracy: 0.9316 - val_loss: 0.2721 - val_accuracy: 0.9274\n",
      "Epoch 69/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2667 - accuracy: 0.9362 - val_loss: 0.2667 - val_accuracy: 0.9338\n",
      "Epoch 70/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2625 - accuracy: 0.9378 - val_loss: 0.2644 - val_accuracy: 0.9338\n",
      "Epoch 71/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2586 - accuracy: 0.9378 - val_loss: 0.2600 - val_accuracy: 0.9338\n",
      "Epoch 72/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2546 - accuracy: 0.9409 - val_loss: 0.2534 - val_accuracy: 0.9401\n",
      "Epoch 73/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2506 - accuracy: 0.9440 - val_loss: 0.2498 - val_accuracy: 0.9432\n",
      "Epoch 74/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2470 - accuracy: 0.9471 - val_loss: 0.2469 - val_accuracy: 0.9432\n",
      "Epoch 75/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2437 - accuracy: 0.9393 - val_loss: 0.2416 - val_accuracy: 0.9464\n",
      "Epoch 76/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2395 - accuracy: 0.9487 - val_loss: 0.2388 - val_accuracy: 0.9464\n",
      "Epoch 77/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2358 - accuracy: 0.9502 - val_loss: 0.2341 - val_accuracy: 0.9464\n",
      "Epoch 78/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2323 - accuracy: 0.9456 - val_loss: 0.2304 - val_accuracy: 0.9464\n",
      "Epoch 79/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2290 - accuracy: 0.9502 - val_loss: 0.2276 - val_accuracy: 0.9464\n",
      "Epoch 80/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2253 - accuracy: 0.9518 - val_loss: 0.2229 - val_accuracy: 0.9464\n",
      "Epoch 81/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2221 - accuracy: 0.9518 - val_loss: 0.2206 - val_accuracy: 0.9464\n",
      "Epoch 82/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2190 - accuracy: 0.9533 - val_loss: 0.2155 - val_accuracy: 0.9464\n",
      "Epoch 83/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2157 - accuracy: 0.9549 - val_loss: 0.2113 - val_accuracy: 0.9464\n",
      "Epoch 84/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2124 - accuracy: 0.9533 - val_loss: 0.2081 - val_accuracy: 0.9495\n",
      "Epoch 85/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2094 - accuracy: 0.9533 - val_loss: 0.2053 - val_accuracy: 0.9495\n",
      "Epoch 86/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2064 - accuracy: 0.9549 - val_loss: 0.2023 - val_accuracy: 0.9495\n",
      "Epoch 87/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2035 - accuracy: 0.9549 - val_loss: 0.1988 - val_accuracy: 0.9495\n",
      "Epoch 88/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2006 - accuracy: 0.9580 - val_loss: 0.1961 - val_accuracy: 0.9495\n",
      "Epoch 89/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1976 - accuracy: 0.9580 - val_loss: 0.1916 - val_accuracy: 0.9558\n",
      "Epoch 90/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1949 - accuracy: 0.9533 - val_loss: 0.1923 - val_accuracy: 0.9527\n",
      "Epoch 91/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1922 - accuracy: 0.9596 - val_loss: 0.1873 - val_accuracy: 0.9590\n",
      "Epoch 92/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1893 - accuracy: 0.9596 - val_loss: 0.1846 - val_accuracy: 0.9590\n",
      "Epoch 93/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.9596 - val_loss: 0.1793 - val_accuracy: 0.9558\n",
      "Epoch 94/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1842 - accuracy: 0.9533 - val_loss: 0.1778 - val_accuracy: 0.9590\n",
      "Epoch 95/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.9565 - val_loss: 0.1744 - val_accuracy: 0.9621\n",
      "Epoch 96/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1789 - accuracy: 0.9549 - val_loss: 0.1717 - val_accuracy: 0.9621\n",
      "Epoch 97/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1768 - accuracy: 0.9518 - val_loss: 0.1718 - val_accuracy: 0.9590\n",
      "Epoch 98/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1750 - accuracy: 0.9580 - val_loss: 0.1685 - val_accuracy: 0.9621\n",
      "Epoch 99/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1720 - accuracy: 0.9596 - val_loss: 0.1666 - val_accuracy: 0.9621\n",
      "Epoch 100/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1694 - accuracy: 0.9533 - val_loss: 0.1615 - val_accuracy: 0.9621\n",
      "(['relu'], [0.9621450901031494])\n",
      "Epoch 1/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7721 - accuracy: 0.4339 - val_loss: 0.7312 - val_accuracy: 0.4763\n",
      "Epoch 2/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7408 - accuracy: 0.4339 - val_loss: 0.7128 - val_accuracy: 0.4763\n",
      "Epoch 3/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7184 - accuracy: 0.4339 - val_loss: 0.7003 - val_accuracy: 0.4763\n",
      "Epoch 4/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7037 - accuracy: 0.4339 - val_loss: 0.6935 - val_accuracy: 0.4763\n",
      "Epoch 5/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4868 - val_loss: 0.6897 - val_accuracy: 0.6467\n",
      "Epoch 6/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5677 - val_loss: 0.6880 - val_accuracy: 0.5237\n",
      "Epoch 7/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6838 - accuracy: 0.5661 - val_loss: 0.6874 - val_accuracy: 0.5237\n",
      "Epoch 8/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6814 - accuracy: 0.5661 - val_loss: 0.6870 - val_accuracy: 0.5237\n",
      "Epoch 9/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6799 - accuracy: 0.5661 - val_loss: 0.6872 - val_accuracy: 0.5237\n",
      "Epoch 10/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6785 - accuracy: 0.5661 - val_loss: 0.6867 - val_accuracy: 0.5237\n",
      "Epoch 11/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6774 - accuracy: 0.5661 - val_loss: 0.6868 - val_accuracy: 0.5237\n",
      "Epoch 12/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6766 - accuracy: 0.5661 - val_loss: 0.6866 - val_accuracy: 0.5237\n",
      "Epoch 13/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6758 - accuracy: 0.5661 - val_loss: 0.6863 - val_accuracy: 0.5237\n",
      "Epoch 14/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6750 - accuracy: 0.5661 - val_loss: 0.6855 - val_accuracy: 0.5237\n",
      "Epoch 15/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6742 - accuracy: 0.5661 - val_loss: 0.6849 - val_accuracy: 0.5237\n",
      "Epoch 16/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6733 - accuracy: 0.5661 - val_loss: 0.6842 - val_accuracy: 0.5237\n",
      "Epoch 17/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6727 - accuracy: 0.5661 - val_loss: 0.6831 - val_accuracy: 0.5237\n",
      "Epoch 18/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6716 - accuracy: 0.5661 - val_loss: 0.6820 - val_accuracy: 0.5237\n",
      "Epoch 19/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6707 - accuracy: 0.5661 - val_loss: 0.6806 - val_accuracy: 0.5237\n",
      "Epoch 20/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6696 - accuracy: 0.5661 - val_loss: 0.6800 - val_accuracy: 0.5237\n",
      "Epoch 21/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6686 - accuracy: 0.5661 - val_loss: 0.6794 - val_accuracy: 0.5237\n",
      "Epoch 22/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6677 - accuracy: 0.5661 - val_loss: 0.6779 - val_accuracy: 0.5237\n",
      "Epoch 23/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6662 - accuracy: 0.5661 - val_loss: 0.6769 - val_accuracy: 0.5237\n",
      "Epoch 24/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6650 - accuracy: 0.5661 - val_loss: 0.6757 - val_accuracy: 0.5237\n",
      "Epoch 25/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6638 - accuracy: 0.5661 - val_loss: 0.6748 - val_accuracy: 0.5237\n",
      "Epoch 26/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6626 - accuracy: 0.5661 - val_loss: 0.6725 - val_accuracy: 0.5237\n",
      "Epoch 27/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6610 - accuracy: 0.5661 - val_loss: 0.6715 - val_accuracy: 0.5237\n",
      "Epoch 28/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6595 - accuracy: 0.5692 - val_loss: 0.6690 - val_accuracy: 0.5237\n",
      "Epoch 29/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6578 - accuracy: 0.5677 - val_loss: 0.6679 - val_accuracy: 0.5268\n",
      "Epoch 30/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6562 - accuracy: 0.5848 - val_loss: 0.6656 - val_accuracy: 0.5331\n",
      "Epoch 31/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6543 - accuracy: 0.5863 - val_loss: 0.6639 - val_accuracy: 0.5363\n",
      "Epoch 32/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6524 - accuracy: 0.5863 - val_loss: 0.6624 - val_accuracy: 0.5363\n",
      "Epoch 33/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6504 - accuracy: 0.5879 - val_loss: 0.6601 - val_accuracy: 0.5363\n",
      "Epoch 34/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.5894 - val_loss: 0.6578 - val_accuracy: 0.5489\n",
      "Epoch 35/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6460 - accuracy: 0.6003 - val_loss: 0.6550 - val_accuracy: 0.5584\n",
      "Epoch 36/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6436 - accuracy: 0.6143 - val_loss: 0.6526 - val_accuracy: 0.5741\n",
      "Epoch 37/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6411 - accuracy: 0.6267 - val_loss: 0.6501 - val_accuracy: 0.5931\n",
      "Epoch 38/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6386 - accuracy: 0.6299 - val_loss: 0.6473 - val_accuracy: 0.5962\n",
      "Epoch 39/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6363 - accuracy: 0.6392 - val_loss: 0.6441 - val_accuracy: 0.6151\n",
      "Epoch 40/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6334 - accuracy: 0.6516 - val_loss: 0.6412 - val_accuracy: 0.6183\n",
      "Epoch 41/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6306 - accuracy: 0.6439 - val_loss: 0.6391 - val_accuracy: 0.6183\n",
      "Epoch 42/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6278 - accuracy: 0.6610 - val_loss: 0.6354 - val_accuracy: 0.6498\n",
      "Epoch 43/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6249 - accuracy: 0.6765 - val_loss: 0.6325 - val_accuracy: 0.6498\n",
      "Epoch 44/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6219 - accuracy: 0.6765 - val_loss: 0.6297 - val_accuracy: 0.6498\n",
      "Epoch 45/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6188 - accuracy: 0.6827 - val_loss: 0.6264 - val_accuracy: 0.6593\n",
      "Epoch 46/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6157 - accuracy: 0.6858 - val_loss: 0.6229 - val_accuracy: 0.6593\n",
      "Epoch 47/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6125 - accuracy: 0.6858 - val_loss: 0.6201 - val_accuracy: 0.6593\n",
      "Epoch 48/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6093 - accuracy: 0.6843 - val_loss: 0.6167 - val_accuracy: 0.6593\n",
      "Epoch 49/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6061 - accuracy: 0.6936 - val_loss: 0.6126 - val_accuracy: 0.6625\n",
      "Epoch 50/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6033 - accuracy: 0.6936 - val_loss: 0.6091 - val_accuracy: 0.6656\n",
      "Epoch 51/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5994 - accuracy: 0.6905 - val_loss: 0.6071 - val_accuracy: 0.6625\n",
      "Epoch 52/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5960 - accuracy: 0.7014 - val_loss: 0.6029 - val_accuracy: 0.6656\n",
      "Epoch 53/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5927 - accuracy: 0.7123 - val_loss: 0.5986 - val_accuracy: 0.6656\n",
      "Epoch 54/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5893 - accuracy: 0.7138 - val_loss: 0.5955 - val_accuracy: 0.6719\n",
      "Epoch 55/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5859 - accuracy: 0.7325 - val_loss: 0.5916 - val_accuracy: 0.6909\n",
      "Epoch 56/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5823 - accuracy: 0.7309 - val_loss: 0.5886 - val_accuracy: 0.6940\n",
      "Epoch 57/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5792 - accuracy: 0.7418 - val_loss: 0.5844 - val_accuracy: 0.7129\n",
      "Epoch 58/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5755 - accuracy: 0.7403 - val_loss: 0.5816 - val_accuracy: 0.7129\n",
      "Epoch 59/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5723 - accuracy: 0.7434 - val_loss: 0.5773 - val_accuracy: 0.7192\n",
      "Epoch 60/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5685 - accuracy: 0.7434 - val_loss: 0.5738 - val_accuracy: 0.7192\n",
      "Epoch 61/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5650 - accuracy: 0.7543 - val_loss: 0.5701 - val_accuracy: 0.7256\n",
      "Epoch 62/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5616 - accuracy: 0.7605 - val_loss: 0.5670 - val_accuracy: 0.7256\n",
      "Epoch 63/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5580 - accuracy: 0.7667 - val_loss: 0.5633 - val_accuracy: 0.7350\n",
      "Epoch 64/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5545 - accuracy: 0.7745 - val_loss: 0.5592 - val_accuracy: 0.7350\n",
      "Epoch 65/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5513 - accuracy: 0.7807 - val_loss: 0.5561 - val_accuracy: 0.7413\n",
      "Epoch 66/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5475 - accuracy: 0.7807 - val_loss: 0.5521 - val_accuracy: 0.7382\n",
      "Epoch 67/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5442 - accuracy: 0.7823 - val_loss: 0.5488 - val_accuracy: 0.7413\n",
      "Epoch 68/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5404 - accuracy: 0.7885 - val_loss: 0.5446 - val_accuracy: 0.7476\n",
      "Epoch 69/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5370 - accuracy: 0.7885 - val_loss: 0.5408 - val_accuracy: 0.7508\n",
      "Epoch 70/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5336 - accuracy: 0.7947 - val_loss: 0.5374 - val_accuracy: 0.7571\n",
      "Epoch 71/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5300 - accuracy: 0.7994 - val_loss: 0.5348 - val_accuracy: 0.7539\n",
      "Epoch 72/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5266 - accuracy: 0.7978 - val_loss: 0.5314 - val_accuracy: 0.7634\n",
      "Epoch 73/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5232 - accuracy: 0.8009 - val_loss: 0.5270 - val_accuracy: 0.7666\n",
      "Epoch 74/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5202 - accuracy: 0.8025 - val_loss: 0.5236 - val_accuracy: 0.7697\n",
      "Epoch 75/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5166 - accuracy: 0.8009 - val_loss: 0.5204 - val_accuracy: 0.7697\n",
      "Epoch 76/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5130 - accuracy: 0.8087 - val_loss: 0.5174 - val_accuracy: 0.7729\n",
      "Epoch 77/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5097 - accuracy: 0.8103 - val_loss: 0.5132 - val_accuracy: 0.7760\n",
      "Epoch 78/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5063 - accuracy: 0.8103 - val_loss: 0.5095 - val_accuracy: 0.7760\n",
      "Epoch 79/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5029 - accuracy: 0.8134 - val_loss: 0.5070 - val_accuracy: 0.7823\n",
      "Epoch 80/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4995 - accuracy: 0.8165 - val_loss: 0.5038 - val_accuracy: 0.7823\n",
      "Epoch 81/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4965 - accuracy: 0.8196 - val_loss: 0.4998 - val_accuracy: 0.7823\n",
      "Epoch 82/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4931 - accuracy: 0.8165 - val_loss: 0.4971 - val_accuracy: 0.7855\n",
      "Epoch 83/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4897 - accuracy: 0.8212 - val_loss: 0.4933 - val_accuracy: 0.7918\n",
      "Epoch 84/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4864 - accuracy: 0.8227 - val_loss: 0.4903 - val_accuracy: 0.7918\n",
      "Epoch 85/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4834 - accuracy: 0.8227 - val_loss: 0.4865 - val_accuracy: 0.7981\n",
      "Epoch 86/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4799 - accuracy: 0.8289 - val_loss: 0.4825 - val_accuracy: 0.8044\n",
      "Epoch 87/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4767 - accuracy: 0.8289 - val_loss: 0.4796 - val_accuracy: 0.8044\n",
      "Epoch 88/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4735 - accuracy: 0.8289 - val_loss: 0.4775 - val_accuracy: 0.7981\n",
      "Epoch 89/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4703 - accuracy: 0.8289 - val_loss: 0.4742 - val_accuracy: 0.8044\n",
      "Epoch 90/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4670 - accuracy: 0.8320 - val_loss: 0.4707 - val_accuracy: 0.8107\n",
      "Epoch 91/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4640 - accuracy: 0.8351 - val_loss: 0.4678 - val_accuracy: 0.8107\n",
      "Epoch 92/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.8367 - val_loss: 0.4637 - val_accuracy: 0.8170\n",
      "Epoch 93/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4578 - accuracy: 0.8320 - val_loss: 0.4612 - val_accuracy: 0.8139\n",
      "Epoch 94/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4552 - accuracy: 0.8476 - val_loss: 0.4563 - val_accuracy: 0.8454\n",
      "Epoch 95/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.8367 - val_loss: 0.4557 - val_accuracy: 0.8202\n",
      "Epoch 96/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4484 - accuracy: 0.8414 - val_loss: 0.4514 - val_accuracy: 0.8391\n",
      "Epoch 97/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4455 - accuracy: 0.8445 - val_loss: 0.4487 - val_accuracy: 0.8391\n",
      "Epoch 98/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4425 - accuracy: 0.8445 - val_loss: 0.4459 - val_accuracy: 0.8391\n",
      "Epoch 99/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4393 - accuracy: 0.8445 - val_loss: 0.4425 - val_accuracy: 0.8517\n",
      "Epoch 100/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4367 - accuracy: 0.8476 - val_loss: 0.4399 - val_accuracy: 0.8454\n",
      "(['relu', 'sigmoid'], [0.9621450901031494, 0.85173499584198])\n",
      "Epoch 1/100\n",
      " 1/65 [..............................] - ETA: 0s - loss: 0.7782 - accuracy: 0.4000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0009s). Check your callbacks.\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.4339 - val_loss: 0.7043 - val_accuracy: 0.4763\n",
      "Epoch 2/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7117 - accuracy: 0.4339 - val_loss: 0.6918 - val_accuracy: 0.4763\n",
      "Epoch 3/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6972 - accuracy: 0.4417 - val_loss: 0.6857 - val_accuracy: 0.5615\n",
      "Epoch 4/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5443 - val_loss: 0.6816 - val_accuracy: 0.7256\n",
      "Epoch 5/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6823 - accuracy: 0.6858 - val_loss: 0.6792 - val_accuracy: 0.5931\n",
      "Epoch 6/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6778 - accuracy: 0.6314 - val_loss: 0.6771 - val_accuracy: 0.5363\n",
      "Epoch 7/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6741 - accuracy: 0.5677 - val_loss: 0.6753 - val_accuracy: 0.5237\n",
      "Epoch 8/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6708 - accuracy: 0.5661 - val_loss: 0.6734 - val_accuracy: 0.5237\n",
      "Epoch 9/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6681 - accuracy: 0.5661 - val_loss: 0.6713 - val_accuracy: 0.5237\n",
      "Epoch 10/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6653 - accuracy: 0.5708 - val_loss: 0.6688 - val_accuracy: 0.5237\n",
      "Epoch 11/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6624 - accuracy: 0.5708 - val_loss: 0.6666 - val_accuracy: 0.5268\n",
      "Epoch 12/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6592 - accuracy: 0.5801 - val_loss: 0.6632 - val_accuracy: 0.5363\n",
      "Epoch 13/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6560 - accuracy: 0.5988 - val_loss: 0.6595 - val_accuracy: 0.5741\n",
      "Epoch 14/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6523 - accuracy: 0.6112 - val_loss: 0.6561 - val_accuracy: 0.5962\n",
      "Epoch 15/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6489 - accuracy: 0.6252 - val_loss: 0.6520 - val_accuracy: 0.6151\n",
      "Epoch 16/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6447 - accuracy: 0.6594 - val_loss: 0.6477 - val_accuracy: 0.6372\n",
      "Epoch 17/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6407 - accuracy: 0.6858 - val_loss: 0.6428 - val_accuracy: 0.6625\n",
      "Epoch 18/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6363 - accuracy: 0.6890 - val_loss: 0.6386 - val_accuracy: 0.6625\n",
      "Epoch 19/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6322 - accuracy: 0.7045 - val_loss: 0.6336 - val_accuracy: 0.6688\n",
      "Epoch 20/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6279 - accuracy: 0.7356 - val_loss: 0.6285 - val_accuracy: 0.6845\n",
      "Epoch 21/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6228 - accuracy: 0.7387 - val_loss: 0.6238 - val_accuracy: 0.6909\n",
      "Epoch 22/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6181 - accuracy: 0.7418 - val_loss: 0.6195 - val_accuracy: 0.6909\n",
      "Epoch 23/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6134 - accuracy: 0.7372 - val_loss: 0.6140 - val_accuracy: 0.7035\n",
      "Epoch 24/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6084 - accuracy: 0.7496 - val_loss: 0.6084 - val_accuracy: 0.7129\n",
      "Epoch 25/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6033 - accuracy: 0.7481 - val_loss: 0.6040 - val_accuracy: 0.7161\n",
      "Epoch 26/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5985 - accuracy: 0.7481 - val_loss: 0.5986 - val_accuracy: 0.7224\n",
      "Epoch 27/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5932 - accuracy: 0.7589 - val_loss: 0.5925 - val_accuracy: 0.7287\n",
      "Epoch 28/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5880 - accuracy: 0.7605 - val_loss: 0.5867 - val_accuracy: 0.7350\n",
      "Epoch 29/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5829 - accuracy: 0.7683 - val_loss: 0.5820 - val_accuracy: 0.7350\n",
      "Epoch 30/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5777 - accuracy: 0.7636 - val_loss: 0.5764 - val_accuracy: 0.7350\n",
      "Epoch 31/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5725 - accuracy: 0.7714 - val_loss: 0.5711 - val_accuracy: 0.7382\n",
      "Epoch 32/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5674 - accuracy: 0.7760 - val_loss: 0.5658 - val_accuracy: 0.7445\n",
      "Epoch 33/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5623 - accuracy: 0.7792 - val_loss: 0.5603 - val_accuracy: 0.7571\n",
      "Epoch 34/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5568 - accuracy: 0.7854 - val_loss: 0.5549 - val_accuracy: 0.7666\n",
      "Epoch 35/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5517 - accuracy: 0.7994 - val_loss: 0.5490 - val_accuracy: 0.7792\n",
      "Epoch 36/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5468 - accuracy: 0.8103 - val_loss: 0.5444 - val_accuracy: 0.7760\n",
      "Epoch 37/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5417 - accuracy: 0.8118 - val_loss: 0.5380 - val_accuracy: 0.7886\n",
      "Epoch 38/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5368 - accuracy: 0.8072 - val_loss: 0.5334 - val_accuracy: 0.7855\n",
      "Epoch 39/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5315 - accuracy: 0.8196 - val_loss: 0.5274 - val_accuracy: 0.8076\n",
      "Epoch 40/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5265 - accuracy: 0.8180 - val_loss: 0.5234 - val_accuracy: 0.8013\n",
      "Epoch 41/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5214 - accuracy: 0.8196 - val_loss: 0.5180 - val_accuracy: 0.8170\n",
      "Epoch 42/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5165 - accuracy: 0.8227 - val_loss: 0.5130 - val_accuracy: 0.8170\n",
      "Epoch 43/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5116 - accuracy: 0.8289 - val_loss: 0.5084 - val_accuracy: 0.8170\n",
      "Epoch 44/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5068 - accuracy: 0.8258 - val_loss: 0.5035 - val_accuracy: 0.8202\n",
      "Epoch 45/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5019 - accuracy: 0.8383 - val_loss: 0.4984 - val_accuracy: 0.8265\n",
      "Epoch 46/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4970 - accuracy: 0.8398 - val_loss: 0.4930 - val_accuracy: 0.8297\n",
      "Epoch 47/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4922 - accuracy: 0.8367 - val_loss: 0.4885 - val_accuracy: 0.8328\n",
      "Epoch 48/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4874 - accuracy: 0.8460 - val_loss: 0.4834 - val_accuracy: 0.8423\n",
      "Epoch 49/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4826 - accuracy: 0.8445 - val_loss: 0.4793 - val_accuracy: 0.8391\n",
      "Epoch 50/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4781 - accuracy: 0.8538 - val_loss: 0.4731 - val_accuracy: 0.8549\n",
      "Epoch 51/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4737 - accuracy: 0.8476 - val_loss: 0.4705 - val_accuracy: 0.8423\n",
      "Epoch 52/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4688 - accuracy: 0.8507 - val_loss: 0.4644 - val_accuracy: 0.8644\n",
      "Epoch 53/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4644 - accuracy: 0.8569 - val_loss: 0.4607 - val_accuracy: 0.8644\n",
      "Epoch 54/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4598 - accuracy: 0.8538 - val_loss: 0.4555 - val_accuracy: 0.8675\n",
      "Epoch 55/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4554 - accuracy: 0.8585 - val_loss: 0.4506 - val_accuracy: 0.8707\n",
      "Epoch 56/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4512 - accuracy: 0.8631 - val_loss: 0.4459 - val_accuracy: 0.8770\n",
      "Epoch 57/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4469 - accuracy: 0.8585 - val_loss: 0.4425 - val_accuracy: 0.8770\n",
      "Epoch 58/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4428 - accuracy: 0.8600 - val_loss: 0.4374 - val_accuracy: 0.8770\n",
      "Epoch 59/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4387 - accuracy: 0.8600 - val_loss: 0.4337 - val_accuracy: 0.8770\n",
      "Epoch 60/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4347 - accuracy: 0.8709 - val_loss: 0.4293 - val_accuracy: 0.8801\n",
      "Epoch 61/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4303 - accuracy: 0.8740 - val_loss: 0.4270 - val_accuracy: 0.8770\n",
      "Epoch 62/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4265 - accuracy: 0.8631 - val_loss: 0.4218 - val_accuracy: 0.8833\n",
      "Epoch 63/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4226 - accuracy: 0.8725 - val_loss: 0.4175 - val_accuracy: 0.8833\n",
      "Epoch 64/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4184 - accuracy: 0.8771 - val_loss: 0.4141 - val_accuracy: 0.8833\n",
      "Epoch 65/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4144 - accuracy: 0.8787 - val_loss: 0.4094 - val_accuracy: 0.8896\n",
      "Epoch 66/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4106 - accuracy: 0.8787 - val_loss: 0.4059 - val_accuracy: 0.8896\n",
      "Epoch 67/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4068 - accuracy: 0.8771 - val_loss: 0.4010 - val_accuracy: 0.8927\n",
      "Epoch 68/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4031 - accuracy: 0.8802 - val_loss: 0.3979 - val_accuracy: 0.8927\n",
      "Epoch 69/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3996 - accuracy: 0.8834 - val_loss: 0.3937 - val_accuracy: 0.8927\n",
      "Epoch 70/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3955 - accuracy: 0.8802 - val_loss: 0.3905 - val_accuracy: 0.8927\n",
      "Epoch 71/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3917 - accuracy: 0.8802 - val_loss: 0.3869 - val_accuracy: 0.8927\n",
      "Epoch 72/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3880 - accuracy: 0.8880 - val_loss: 0.3823 - val_accuracy: 0.8959\n",
      "Epoch 73/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3843 - accuracy: 0.8865 - val_loss: 0.3786 - val_accuracy: 0.8959\n",
      "Epoch 74/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3809 - accuracy: 0.8880 - val_loss: 0.3759 - val_accuracy: 0.8959\n",
      "Epoch 75/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3773 - accuracy: 0.8896 - val_loss: 0.3724 - val_accuracy: 0.8959\n",
      "Epoch 76/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3736 - accuracy: 0.8911 - val_loss: 0.3680 - val_accuracy: 0.9022\n",
      "Epoch 77/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3700 - accuracy: 0.8927 - val_loss: 0.3647 - val_accuracy: 0.9022\n",
      "Epoch 78/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3666 - accuracy: 0.8911 - val_loss: 0.3609 - val_accuracy: 0.8991\n",
      "Epoch 79/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3632 - accuracy: 0.8911 - val_loss: 0.3571 - val_accuracy: 0.9022\n",
      "Epoch 80/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3600 - accuracy: 0.8942 - val_loss: 0.3533 - val_accuracy: 0.9022\n",
      "Epoch 81/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3567 - accuracy: 0.8942 - val_loss: 0.3502 - val_accuracy: 0.9022\n",
      "Epoch 82/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3530 - accuracy: 0.8958 - val_loss: 0.3469 - val_accuracy: 0.9022\n",
      "Epoch 83/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3500 - accuracy: 0.8958 - val_loss: 0.3439 - val_accuracy: 0.9022\n",
      "Epoch 84/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3466 - accuracy: 0.8989 - val_loss: 0.3402 - val_accuracy: 0.9054\n",
      "Epoch 85/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3437 - accuracy: 0.8989 - val_loss: 0.3384 - val_accuracy: 0.9022\n",
      "Epoch 86/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3404 - accuracy: 0.9051 - val_loss: 0.3350 - val_accuracy: 0.9085\n",
      "Epoch 87/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3374 - accuracy: 0.9051 - val_loss: 0.3311 - val_accuracy: 0.9085\n",
      "Epoch 88/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3343 - accuracy: 0.9067 - val_loss: 0.3281 - val_accuracy: 0.9117\n",
      "Epoch 89/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.9082 - val_loss: 0.3245 - val_accuracy: 0.9117\n",
      "Epoch 90/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.9098 - val_loss: 0.3219 - val_accuracy: 0.9117\n",
      "Epoch 91/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3251 - accuracy: 0.9114 - val_loss: 0.3183 - val_accuracy: 0.9180\n",
      "Epoch 92/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3228 - accuracy: 0.9176 - val_loss: 0.3150 - val_accuracy: 0.9180\n",
      "Epoch 93/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3195 - accuracy: 0.9145 - val_loss: 0.3135 - val_accuracy: 0.9180\n",
      "Epoch 94/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3165 - accuracy: 0.9191 - val_loss: 0.3098 - val_accuracy: 0.9211\n",
      "Epoch 95/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3137 - accuracy: 0.9222 - val_loss: 0.3071 - val_accuracy: 0.9211\n",
      "Epoch 96/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3112 - accuracy: 0.9238 - val_loss: 0.3042 - val_accuracy: 0.9211\n",
      "Epoch 97/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3079 - accuracy: 0.9207 - val_loss: 0.3014 - val_accuracy: 0.9243\n",
      "Epoch 98/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3052 - accuracy: 0.9222 - val_loss: 0.2973 - val_accuracy: 0.9243\n",
      "Epoch 99/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3026 - accuracy: 0.9238 - val_loss: 0.2953 - val_accuracy: 0.9243\n",
      "Epoch 100/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2998 - accuracy: 0.9285 - val_loss: 0.2922 - val_accuracy: 0.9274\n",
      "(['relu', 'sigmoid', 'softmax'], [0.9621450901031494, 0.85173499584198, 0.9274448156356812])\n",
      "Epoch 1/100\n",
      " 1/65 [..............................] - ETA: 0s - loss: 0.8667 - accuracy: 0.3000WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6633 - accuracy: 0.5661 - val_loss: 0.6682 - val_accuracy: 0.5237\n",
      "Epoch 2/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6562 - accuracy: 0.5661 - val_loss: 0.6590 - val_accuracy: 0.5237\n",
      "Epoch 3/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6506 - accuracy: 0.5677 - val_loss: 0.6527 - val_accuracy: 0.5268\n",
      "Epoch 4/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6455 - accuracy: 0.5848 - val_loss: 0.6470 - val_accuracy: 0.5457\n",
      "Epoch 5/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6406 - accuracy: 0.6190 - val_loss: 0.6404 - val_accuracy: 0.5899\n",
      "Epoch 6/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6351 - accuracy: 0.6516 - val_loss: 0.6363 - val_accuracy: 0.5994\n",
      "Epoch 7/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6303 - accuracy: 0.6672 - val_loss: 0.6304 - val_accuracy: 0.6404\n",
      "Epoch 8/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6249 - accuracy: 0.6687 - val_loss: 0.6249 - val_accuracy: 0.6530\n",
      "Epoch 9/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6192 - accuracy: 0.6812 - val_loss: 0.6198 - val_accuracy: 0.6562\n",
      "Epoch 10/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6138 - accuracy: 0.6905 - val_loss: 0.6141 - val_accuracy: 0.6593\n",
      "Epoch 11/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6082 - accuracy: 0.6952 - val_loss: 0.6084 - val_accuracy: 0.6625\n",
      "Epoch 12/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6029 - accuracy: 0.7061 - val_loss: 0.6021 - val_accuracy: 0.6625\n",
      "Epoch 13/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5967 - accuracy: 0.7092 - val_loss: 0.5959 - val_accuracy: 0.6751\n",
      "Epoch 14/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5906 - accuracy: 0.7309 - val_loss: 0.5896 - val_accuracy: 0.6877\n",
      "Epoch 15/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5849 - accuracy: 0.7216 - val_loss: 0.5835 - val_accuracy: 0.6940\n",
      "Epoch 16/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5783 - accuracy: 0.7481 - val_loss: 0.5762 - val_accuracy: 0.7066\n",
      "Epoch 17/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5722 - accuracy: 0.7543 - val_loss: 0.5702 - val_accuracy: 0.7161\n",
      "Epoch 18/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5658 - accuracy: 0.7605 - val_loss: 0.5635 - val_accuracy: 0.7224\n",
      "Epoch 19/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5595 - accuracy: 0.7589 - val_loss: 0.5581 - val_accuracy: 0.7224\n",
      "Epoch 20/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5528 - accuracy: 0.7667 - val_loss: 0.5498 - val_accuracy: 0.7287\n",
      "Epoch 21/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5468 - accuracy: 0.7667 - val_loss: 0.5438 - val_accuracy: 0.7319\n",
      "Epoch 22/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5399 - accuracy: 0.7760 - val_loss: 0.5367 - val_accuracy: 0.7413\n",
      "Epoch 23/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5335 - accuracy: 0.7792 - val_loss: 0.5305 - val_accuracy: 0.7445\n",
      "Epoch 24/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5271 - accuracy: 0.7807 - val_loss: 0.5236 - val_accuracy: 0.7539\n",
      "Epoch 25/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5208 - accuracy: 0.7947 - val_loss: 0.5154 - val_accuracy: 0.7760\n",
      "Epoch 26/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5135 - accuracy: 0.7978 - val_loss: 0.5098 - val_accuracy: 0.7697\n",
      "Epoch 27/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5073 - accuracy: 0.7963 - val_loss: 0.5035 - val_accuracy: 0.7729\n",
      "Epoch 28/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5010 - accuracy: 0.7994 - val_loss: 0.4967 - val_accuracy: 0.7792\n",
      "Epoch 29/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4944 - accuracy: 0.8040 - val_loss: 0.4911 - val_accuracy: 0.7792\n",
      "Epoch 30/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4877 - accuracy: 0.8180 - val_loss: 0.4831 - val_accuracy: 0.8013\n",
      "Epoch 31/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.8289 - val_loss: 0.4773 - val_accuracy: 0.8044\n",
      "Epoch 32/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4750 - accuracy: 0.8274 - val_loss: 0.4718 - val_accuracy: 0.8076\n",
      "Epoch 33/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4692 - accuracy: 0.8320 - val_loss: 0.4658 - val_accuracy: 0.8170\n",
      "Epoch 34/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4627 - accuracy: 0.8305 - val_loss: 0.4590 - val_accuracy: 0.8233\n",
      "Epoch 35/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4568 - accuracy: 0.8367 - val_loss: 0.4528 - val_accuracy: 0.8265\n",
      "Epoch 36/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4514 - accuracy: 0.8414 - val_loss: 0.4464 - val_accuracy: 0.8391\n",
      "Epoch 37/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4451 - accuracy: 0.8476 - val_loss: 0.4417 - val_accuracy: 0.8297\n",
      "Epoch 38/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4394 - accuracy: 0.8507 - val_loss: 0.4365 - val_accuracy: 0.8423\n",
      "Epoch 39/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4335 - accuracy: 0.8523 - val_loss: 0.4288 - val_accuracy: 0.8675\n",
      "Epoch 40/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.8647 - val_loss: 0.4235 - val_accuracy: 0.8707\n",
      "Epoch 41/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4225 - accuracy: 0.8569 - val_loss: 0.4183 - val_accuracy: 0.8770\n",
      "Epoch 42/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4170 - accuracy: 0.8600 - val_loss: 0.4130 - val_accuracy: 0.8770\n",
      "Epoch 43/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4122 - accuracy: 0.8616 - val_loss: 0.4074 - val_accuracy: 0.8770\n",
      "Epoch 44/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4069 - accuracy: 0.8725 - val_loss: 0.4007 - val_accuracy: 0.8801\n",
      "Epoch 45/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4026 - accuracy: 0.8631 - val_loss: 0.3961 - val_accuracy: 0.8833\n",
      "Epoch 46/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3966 - accuracy: 0.8709 - val_loss: 0.3913 - val_accuracy: 0.8833\n",
      "Epoch 47/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3911 - accuracy: 0.8740 - val_loss: 0.3865 - val_accuracy: 0.8864\n",
      "Epoch 48/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3868 - accuracy: 0.8834 - val_loss: 0.3828 - val_accuracy: 0.8864\n",
      "Epoch 49/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3813 - accuracy: 0.8818 - val_loss: 0.3774 - val_accuracy: 0.8896\n",
      "Epoch 50/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3770 - accuracy: 0.8787 - val_loss: 0.3726 - val_accuracy: 0.8896\n",
      "Epoch 51/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3719 - accuracy: 0.8834 - val_loss: 0.3678 - val_accuracy: 0.8927\n",
      "Epoch 52/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3674 - accuracy: 0.8880 - val_loss: 0.3634 - val_accuracy: 0.8927\n",
      "Epoch 53/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3634 - accuracy: 0.8834 - val_loss: 0.3601 - val_accuracy: 0.8959\n",
      "Epoch 54/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3584 - accuracy: 0.8849 - val_loss: 0.3557 - val_accuracy: 0.8959\n",
      "Epoch 55/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3538 - accuracy: 0.8865 - val_loss: 0.3500 - val_accuracy: 0.8991\n",
      "Epoch 56/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3505 - accuracy: 0.8896 - val_loss: 0.3474 - val_accuracy: 0.9022\n",
      "Epoch 57/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3456 - accuracy: 0.8942 - val_loss: 0.3429 - val_accuracy: 0.9022\n",
      "Epoch 58/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3417 - accuracy: 0.8896 - val_loss: 0.3370 - val_accuracy: 0.9085\n",
      "Epoch 59/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3375 - accuracy: 0.8974 - val_loss: 0.3323 - val_accuracy: 0.9054\n",
      "Epoch 60/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8989 - val_loss: 0.3294 - val_accuracy: 0.9085\n",
      "Epoch 61/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8974 - val_loss: 0.3288 - val_accuracy: 0.9022\n",
      "Epoch 62/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3258 - accuracy: 0.9005 - val_loss: 0.3215 - val_accuracy: 0.9117\n",
      "Epoch 63/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3219 - accuracy: 0.9051 - val_loss: 0.3189 - val_accuracy: 0.9117\n",
      "Epoch 64/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3185 - accuracy: 0.9114 - val_loss: 0.3151 - val_accuracy: 0.9117\n",
      "Epoch 65/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3144 - accuracy: 0.9160 - val_loss: 0.3107 - val_accuracy: 0.9148\n",
      "Epoch 66/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3105 - accuracy: 0.9145 - val_loss: 0.3082 - val_accuracy: 0.9117\n",
      "Epoch 67/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3072 - accuracy: 0.9191 - val_loss: 0.3027 - val_accuracy: 0.9243\n",
      "Epoch 68/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3037 - accuracy: 0.9207 - val_loss: 0.2992 - val_accuracy: 0.9274\n",
      "Epoch 69/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3005 - accuracy: 0.9238 - val_loss: 0.2970 - val_accuracy: 0.9180\n",
      "Epoch 70/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2971 - accuracy: 0.9222 - val_loss: 0.2925 - val_accuracy: 0.9243\n",
      "Epoch 71/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2948 - accuracy: 0.9269 - val_loss: 0.2895 - val_accuracy: 0.9243\n",
      "Epoch 72/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2904 - accuracy: 0.9285 - val_loss: 0.2886 - val_accuracy: 0.9180\n",
      "Epoch 73/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2870 - accuracy: 0.9285 - val_loss: 0.2843 - val_accuracy: 0.9243\n",
      "Epoch 74/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2840 - accuracy: 0.9300 - val_loss: 0.2794 - val_accuracy: 0.9306\n",
      "Epoch 75/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2805 - accuracy: 0.9300 - val_loss: 0.2773 - val_accuracy: 0.9274\n",
      "Epoch 76/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2777 - accuracy: 0.9316 - val_loss: 0.2739 - val_accuracy: 0.9306\n",
      "Epoch 77/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2749 - accuracy: 0.9378 - val_loss: 0.2727 - val_accuracy: 0.9274\n",
      "Epoch 78/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2717 - accuracy: 0.9316 - val_loss: 0.2684 - val_accuracy: 0.9306\n",
      "Epoch 79/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2685 - accuracy: 0.9347 - val_loss: 0.2639 - val_accuracy: 0.9338\n",
      "Epoch 80/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2660 - accuracy: 0.9393 - val_loss: 0.2617 - val_accuracy: 0.9338\n",
      "Epoch 81/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2630 - accuracy: 0.9393 - val_loss: 0.2587 - val_accuracy: 0.9369\n",
      "Epoch 82/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2602 - accuracy: 0.9393 - val_loss: 0.2580 - val_accuracy: 0.9306\n",
      "Epoch 83/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2574 - accuracy: 0.9393 - val_loss: 0.2528 - val_accuracy: 0.9432\n",
      "Epoch 84/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2545 - accuracy: 0.9393 - val_loss: 0.2484 - val_accuracy: 0.9432\n",
      "Epoch 85/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2524 - accuracy: 0.9378 - val_loss: 0.2496 - val_accuracy: 0.9369\n",
      "Epoch 86/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2497 - accuracy: 0.9393 - val_loss: 0.2464 - val_accuracy: 0.9432\n",
      "Epoch 87/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2468 - accuracy: 0.9425 - val_loss: 0.2424 - val_accuracy: 0.9432\n",
      "Epoch 88/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2447 - accuracy: 0.9409 - val_loss: 0.2400 - val_accuracy: 0.9432\n",
      "Epoch 89/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2418 - accuracy: 0.9425 - val_loss: 0.2359 - val_accuracy: 0.9432\n",
      "Epoch 90/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2392 - accuracy: 0.9425 - val_loss: 0.2339 - val_accuracy: 0.9432\n",
      "Epoch 91/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2374 - accuracy: 0.9425 - val_loss: 0.2312 - val_accuracy: 0.9432\n",
      "Epoch 92/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2343 - accuracy: 0.9440 - val_loss: 0.2300 - val_accuracy: 0.9432\n",
      "Epoch 93/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2322 - accuracy: 0.9456 - val_loss: 0.2266 - val_accuracy: 0.9432\n",
      "Epoch 94/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2298 - accuracy: 0.9440 - val_loss: 0.2238 - val_accuracy: 0.9432\n",
      "Epoch 95/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2274 - accuracy: 0.9471 - val_loss: 0.2221 - val_accuracy: 0.9464\n",
      "Epoch 96/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2253 - accuracy: 0.9471 - val_loss: 0.2197 - val_accuracy: 0.9464\n",
      "Epoch 97/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2233 - accuracy: 0.9487 - val_loss: 0.2166 - val_accuracy: 0.9495\n",
      "Epoch 98/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2213 - accuracy: 0.9487 - val_loss: 0.2140 - val_accuracy: 0.9495\n",
      "Epoch 99/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2187 - accuracy: 0.9502 - val_loss: 0.2131 - val_accuracy: 0.9495\n",
      "Epoch 100/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2171 - accuracy: 0.9487 - val_loss: 0.2113 - val_accuracy: 0.9495\n",
      "(['relu', 'sigmoid', 'softmax', 'softplus'], [0.9621450901031494, 0.85173499584198, 0.9274448156356812, 0.9495267868041992])\n",
      "Epoch 1/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.5925 - val_loss: 0.6897 - val_accuracy: 0.5237\n",
      "Epoch 2/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6598 - accuracy: 0.5941 - val_loss: 0.6790 - val_accuracy: 0.5331\n",
      "Epoch 3/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6507 - accuracy: 0.6081 - val_loss: 0.6686 - val_accuracy: 0.5457\n",
      "Epoch 4/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6404 - accuracy: 0.6112 - val_loss: 0.6581 - val_accuracy: 0.5489\n",
      "Epoch 5/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6306 - accuracy: 0.6143 - val_loss: 0.6467 - val_accuracy: 0.5521\n",
      "Epoch 6/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6209 - accuracy: 0.6267 - val_loss: 0.6359 - val_accuracy: 0.5710\n",
      "Epoch 7/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6113 - accuracy: 0.6392 - val_loss: 0.6255 - val_accuracy: 0.5899\n",
      "Epoch 8/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6013 - accuracy: 0.6501 - val_loss: 0.6160 - val_accuracy: 0.5962\n",
      "Epoch 9/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5915 - accuracy: 0.6563 - val_loss: 0.6059 - val_accuracy: 0.6309\n",
      "Epoch 10/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5819 - accuracy: 0.7403 - val_loss: 0.5941 - val_accuracy: 0.6688\n",
      "Epoch 11/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5715 - accuracy: 0.7465 - val_loss: 0.5817 - val_accuracy: 0.7256\n",
      "Epoch 12/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5603 - accuracy: 0.7932 - val_loss: 0.5707 - val_accuracy: 0.7539\n",
      "Epoch 13/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5491 - accuracy: 0.7994 - val_loss: 0.5593 - val_accuracy: 0.7760\n",
      "Epoch 14/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5387 - accuracy: 0.8118 - val_loss: 0.5473 - val_accuracy: 0.7886\n",
      "Epoch 15/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5291 - accuracy: 0.8258 - val_loss: 0.5378 - val_accuracy: 0.7950\n",
      "Epoch 16/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5196 - accuracy: 0.8305 - val_loss: 0.5289 - val_accuracy: 0.7981\n",
      "Epoch 17/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5108 - accuracy: 0.8289 - val_loss: 0.5203 - val_accuracy: 0.8044\n",
      "Epoch 18/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5019 - accuracy: 0.8320 - val_loss: 0.5101 - val_accuracy: 0.8139\n",
      "Epoch 19/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4931 - accuracy: 0.8383 - val_loss: 0.5007 - val_accuracy: 0.8265\n",
      "Epoch 20/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.8445 - val_loss: 0.4944 - val_accuracy: 0.8139\n",
      "Epoch 21/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4765 - accuracy: 0.8414 - val_loss: 0.4827 - val_accuracy: 0.8360\n",
      "Epoch 22/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4682 - accuracy: 0.8460 - val_loss: 0.4740 - val_accuracy: 0.8391\n",
      "Epoch 23/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.8523 - val_loss: 0.4654 - val_accuracy: 0.8517\n",
      "Epoch 24/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4517 - accuracy: 0.8554 - val_loss: 0.4567 - val_accuracy: 0.8580\n",
      "Epoch 25/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4435 - accuracy: 0.8585 - val_loss: 0.4493 - val_accuracy: 0.8580\n",
      "Epoch 26/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4357 - accuracy: 0.8616 - val_loss: 0.4402 - val_accuracy: 0.8707\n",
      "Epoch 27/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.8709 - val_loss: 0.4335 - val_accuracy: 0.8675\n",
      "Epoch 28/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4206 - accuracy: 0.8709 - val_loss: 0.4250 - val_accuracy: 0.8738\n",
      "Epoch 29/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4132 - accuracy: 0.8725 - val_loss: 0.4198 - val_accuracy: 0.8707\n",
      "Epoch 30/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4058 - accuracy: 0.8725 - val_loss: 0.4085 - val_accuracy: 0.8738\n",
      "Epoch 31/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3982 - accuracy: 0.8771 - val_loss: 0.4001 - val_accuracy: 0.8770\n",
      "Epoch 32/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3910 - accuracy: 0.8818 - val_loss: 0.3923 - val_accuracy: 0.8833\n",
      "Epoch 33/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3840 - accuracy: 0.8818 - val_loss: 0.3852 - val_accuracy: 0.8833\n",
      "Epoch 34/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3770 - accuracy: 0.8818 - val_loss: 0.3789 - val_accuracy: 0.8864\n",
      "Epoch 35/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3704 - accuracy: 0.8849 - val_loss: 0.3718 - val_accuracy: 0.8864\n",
      "Epoch 36/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3634 - accuracy: 0.8865 - val_loss: 0.3653 - val_accuracy: 0.8927\n",
      "Epoch 37/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3571 - accuracy: 0.8896 - val_loss: 0.3575 - val_accuracy: 0.8896\n",
      "Epoch 38/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3507 - accuracy: 0.9067 - val_loss: 0.3509 - val_accuracy: 0.8959\n",
      "Epoch 39/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3446 - accuracy: 0.9036 - val_loss: 0.3428 - val_accuracy: 0.8959\n",
      "Epoch 40/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3382 - accuracy: 0.9114 - val_loss: 0.3368 - val_accuracy: 0.9022\n",
      "Epoch 41/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.9145 - val_loss: 0.3314 - val_accuracy: 0.8991\n",
      "Epoch 42/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3259 - accuracy: 0.9129 - val_loss: 0.3232 - val_accuracy: 0.9148\n",
      "Epoch 43/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3202 - accuracy: 0.9176 - val_loss: 0.3192 - val_accuracy: 0.9117\n",
      "Epoch 44/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3148 - accuracy: 0.9207 - val_loss: 0.3115 - val_accuracy: 0.9180\n",
      "Epoch 45/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3086 - accuracy: 0.9238 - val_loss: 0.3080 - val_accuracy: 0.9148\n",
      "Epoch 46/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3027 - accuracy: 0.9285 - val_loss: 0.2993 - val_accuracy: 0.9243\n",
      "Epoch 47/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2978 - accuracy: 0.9316 - val_loss: 0.2940 - val_accuracy: 0.9243\n",
      "Epoch 48/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2922 - accuracy: 0.9300 - val_loss: 0.2908 - val_accuracy: 0.9211\n",
      "Epoch 49/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2871 - accuracy: 0.9285 - val_loss: 0.2821 - val_accuracy: 0.9338\n",
      "Epoch 50/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2817 - accuracy: 0.9362 - val_loss: 0.2781 - val_accuracy: 0.9338\n",
      "Epoch 51/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2773 - accuracy: 0.9378 - val_loss: 0.2702 - val_accuracy: 0.9369\n",
      "Epoch 52/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2725 - accuracy: 0.9393 - val_loss: 0.2667 - val_accuracy: 0.9369\n",
      "Epoch 53/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2669 - accuracy: 0.9409 - val_loss: 0.2614 - val_accuracy: 0.9401\n",
      "Epoch 54/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2622 - accuracy: 0.9409 - val_loss: 0.2582 - val_accuracy: 0.9369\n",
      "Epoch 55/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2580 - accuracy: 0.9409 - val_loss: 0.2513 - val_accuracy: 0.9401\n",
      "Epoch 56/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2531 - accuracy: 0.9409 - val_loss: 0.2469 - val_accuracy: 0.9401\n",
      "Epoch 57/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2485 - accuracy: 0.9409 - val_loss: 0.2431 - val_accuracy: 0.9401\n",
      "Epoch 58/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2445 - accuracy: 0.9409 - val_loss: 0.2393 - val_accuracy: 0.9401\n",
      "Epoch 59/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2402 - accuracy: 0.9425 - val_loss: 0.2358 - val_accuracy: 0.9432\n",
      "Epoch 60/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2358 - accuracy: 0.9456 - val_loss: 0.2254 - val_accuracy: 0.9464\n",
      "Epoch 61/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2323 - accuracy: 0.9378 - val_loss: 0.2257 - val_accuracy: 0.9464\n",
      "Epoch 62/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2281 - accuracy: 0.9471 - val_loss: 0.2179 - val_accuracy: 0.9464\n",
      "Epoch 63/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2244 - accuracy: 0.9456 - val_loss: 0.2141 - val_accuracy: 0.9464\n",
      "Epoch 64/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2202 - accuracy: 0.9456 - val_loss: 0.2127 - val_accuracy: 0.9527\n",
      "Epoch 65/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2167 - accuracy: 0.9487 - val_loss: 0.2079 - val_accuracy: 0.9527\n",
      "Epoch 66/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2131 - accuracy: 0.9502 - val_loss: 0.2058 - val_accuracy: 0.9527\n",
      "Epoch 67/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2093 - accuracy: 0.9518 - val_loss: 0.2005 - val_accuracy: 0.9527\n",
      "Epoch 68/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2057 - accuracy: 0.9533 - val_loss: 0.1952 - val_accuracy: 0.9558\n",
      "Epoch 69/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2025 - accuracy: 0.9502 - val_loss: 0.1923 - val_accuracy: 0.9558\n",
      "Epoch 70/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1991 - accuracy: 0.9549 - val_loss: 0.1887 - val_accuracy: 0.9558\n",
      "Epoch 71/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1956 - accuracy: 0.9471 - val_loss: 0.1864 - val_accuracy: 0.9558\n",
      "Epoch 72/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1927 - accuracy: 0.9565 - val_loss: 0.1822 - val_accuracy: 0.9590\n",
      "Epoch 73/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1902 - accuracy: 0.9502 - val_loss: 0.1824 - val_accuracy: 0.9558\n",
      "Epoch 74/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.9565 - val_loss: 0.1754 - val_accuracy: 0.9590\n",
      "Epoch 75/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1835 - accuracy: 0.9549 - val_loss: 0.1706 - val_accuracy: 0.9590\n",
      "Epoch 76/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1815 - accuracy: 0.9502 - val_loss: 0.1680 - val_accuracy: 0.9590\n",
      "Epoch 77/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1773 - accuracy: 0.9518 - val_loss: 0.1684 - val_accuracy: 0.9621\n",
      "Epoch 78/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1746 - accuracy: 0.9580 - val_loss: 0.1617 - val_accuracy: 0.9590\n",
      "Epoch 79/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1724 - accuracy: 0.9487 - val_loss: 0.1609 - val_accuracy: 0.9590\n",
      "Epoch 80/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1693 - accuracy: 0.9549 - val_loss: 0.1581 - val_accuracy: 0.9590\n",
      "Epoch 81/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1666 - accuracy: 0.9533 - val_loss: 0.1541 - val_accuracy: 0.9590\n",
      "Epoch 82/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1647 - accuracy: 0.9533 - val_loss: 0.1527 - val_accuracy: 0.9621\n",
      "Epoch 83/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1622 - accuracy: 0.9533 - val_loss: 0.1508 - val_accuracy: 0.9621\n",
      "Epoch 84/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1591 - accuracy: 0.9518 - val_loss: 0.1484 - val_accuracy: 0.9621\n",
      "Epoch 85/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1568 - accuracy: 0.9596 - val_loss: 0.1436 - val_accuracy: 0.9653\n",
      "Epoch 86/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1544 - accuracy: 0.9533 - val_loss: 0.1415 - val_accuracy: 0.9653\n",
      "Epoch 87/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1522 - accuracy: 0.9549 - val_loss: 0.1438 - val_accuracy: 0.9653\n",
      "Epoch 88/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1509 - accuracy: 0.9549 - val_loss: 0.1384 - val_accuracy: 0.9653\n",
      "Epoch 89/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1484 - accuracy: 0.9565 - val_loss: 0.1371 - val_accuracy: 0.9685\n",
      "Epoch 90/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1452 - accuracy: 0.9565 - val_loss: 0.1319 - val_accuracy: 0.9653\n",
      "Epoch 91/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1435 - accuracy: 0.9627 - val_loss: 0.1292 - val_accuracy: 0.9685\n",
      "Epoch 92/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1409 - accuracy: 0.9596 - val_loss: 0.1279 - val_accuracy: 0.9653\n",
      "Epoch 93/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1393 - accuracy: 0.9580 - val_loss: 0.1245 - val_accuracy: 0.9685\n",
      "Epoch 94/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1373 - accuracy: 0.9611 - val_loss: 0.1235 - val_accuracy: 0.9685\n",
      "Epoch 95/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1359 - accuracy: 0.9627 - val_loss: 0.1226 - val_accuracy: 0.9653\n",
      "Epoch 96/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1337 - accuracy: 0.9611 - val_loss: 0.1220 - val_accuracy: 0.9653\n",
      "Epoch 97/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1315 - accuracy: 0.9658 - val_loss: 0.1198 - val_accuracy: 0.9653\n",
      "Epoch 98/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1301 - accuracy: 0.9627 - val_loss: 0.1141 - val_accuracy: 0.9716\n",
      "Epoch 99/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1279 - accuracy: 0.9658 - val_loss: 0.1140 - val_accuracy: 0.9685\n",
      "Epoch 100/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1261 - accuracy: 0.9673 - val_loss: 0.1163 - val_accuracy: 0.9685\n",
      "(['relu', 'sigmoid', 'softmax', 'softplus', 'softsign'], [0.9621450901031494, 0.85173499584198, 0.9274448156356812, 0.9495267868041992, 0.9716088175773621])\n",
      "Epoch 1/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7606 - accuracy: 0.4323 - val_loss: 0.7145 - val_accuracy: 0.4795\n",
      "Epoch 2/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7234 - accuracy: 0.4075 - val_loss: 0.6938 - val_accuracy: 0.5079\n",
      "Epoch 3/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6999 - accuracy: 0.4386 - val_loss: 0.6847 - val_accuracy: 0.5110\n",
      "Epoch 4/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.5848 - val_loss: 0.6808 - val_accuracy: 0.6088\n",
      "Epoch 5/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6794 - accuracy: 0.6345 - val_loss: 0.6790 - val_accuracy: 0.5899\n",
      "Epoch 6/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6743 - accuracy: 0.6283 - val_loss: 0.6765 - val_accuracy: 0.5773\n",
      "Epoch 7/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6701 - accuracy: 0.6050 - val_loss: 0.6736 - val_accuracy: 0.5741\n",
      "Epoch 8/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6656 - accuracy: 0.6190 - val_loss: 0.6703 - val_accuracy: 0.5836\n",
      "Epoch 9/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6611 - accuracy: 0.6345 - val_loss: 0.6658 - val_accuracy: 0.6025\n",
      "Epoch 10/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6560 - accuracy: 0.6345 - val_loss: 0.6621 - val_accuracy: 0.6025\n",
      "Epoch 11/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6512 - accuracy: 0.6423 - val_loss: 0.6560 - val_accuracy: 0.6088\n",
      "Epoch 12/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6450 - accuracy: 0.6439 - val_loss: 0.6512 - val_accuracy: 0.6151\n",
      "Epoch 13/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6392 - accuracy: 0.6516 - val_loss: 0.6445 - val_accuracy: 0.6246\n",
      "Epoch 14/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6325 - accuracy: 0.6750 - val_loss: 0.6372 - val_accuracy: 0.6530\n",
      "Epoch 15/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6260 - accuracy: 0.6719 - val_loss: 0.6300 - val_accuracy: 0.6593\n",
      "Epoch 16/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6182 - accuracy: 0.6734 - val_loss: 0.6224 - val_accuracy: 0.6498\n",
      "Epoch 17/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6108 - accuracy: 0.6765 - val_loss: 0.6155 - val_accuracy: 0.6530\n",
      "Epoch 18/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6029 - accuracy: 0.6750 - val_loss: 0.6084 - val_accuracy: 0.6530\n",
      "Epoch 19/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5950 - accuracy: 0.6812 - val_loss: 0.6003 - val_accuracy: 0.6530\n",
      "Epoch 20/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5869 - accuracy: 0.6796 - val_loss: 0.5915 - val_accuracy: 0.6435\n",
      "Epoch 21/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5788 - accuracy: 0.6998 - val_loss: 0.5826 - val_accuracy: 0.6688\n",
      "Epoch 22/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5705 - accuracy: 0.7107 - val_loss: 0.5749 - val_accuracy: 0.6845\n",
      "Epoch 23/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5620 - accuracy: 0.7216 - val_loss: 0.5674 - val_accuracy: 0.6940\n",
      "Epoch 24/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5534 - accuracy: 0.7387 - val_loss: 0.5576 - val_accuracy: 0.7129\n",
      "Epoch 25/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5447 - accuracy: 0.7574 - val_loss: 0.5482 - val_accuracy: 0.7287\n",
      "Epoch 26/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5354 - accuracy: 0.7729 - val_loss: 0.5405 - val_accuracy: 0.7287\n",
      "Epoch 27/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5270 - accuracy: 0.7760 - val_loss: 0.5309 - val_accuracy: 0.7413\n",
      "Epoch 28/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5183 - accuracy: 0.7900 - val_loss: 0.5218 - val_accuracy: 0.7476\n",
      "Epoch 29/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5091 - accuracy: 0.7932 - val_loss: 0.5149 - val_accuracy: 0.7539\n",
      "Epoch 30/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5011 - accuracy: 0.7947 - val_loss: 0.5039 - val_accuracy: 0.7697\n",
      "Epoch 31/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4917 - accuracy: 0.8072 - val_loss: 0.4960 - val_accuracy: 0.7729\n",
      "Epoch 32/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4831 - accuracy: 0.8134 - val_loss: 0.4883 - val_accuracy: 0.7760\n",
      "Epoch 33/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4744 - accuracy: 0.8180 - val_loss: 0.4797 - val_accuracy: 0.7823\n",
      "Epoch 34/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4665 - accuracy: 0.8196 - val_loss: 0.4709 - val_accuracy: 0.7950\n",
      "Epoch 35/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4576 - accuracy: 0.8289 - val_loss: 0.4630 - val_accuracy: 0.7950\n",
      "Epoch 36/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4489 - accuracy: 0.8305 - val_loss: 0.4534 - val_accuracy: 0.8139\n",
      "Epoch 37/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4408 - accuracy: 0.8398 - val_loss: 0.4474 - val_accuracy: 0.8076\n",
      "Epoch 38/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4325 - accuracy: 0.8351 - val_loss: 0.4379 - val_accuracy: 0.8328\n",
      "Epoch 39/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4250 - accuracy: 0.8414 - val_loss: 0.4284 - val_accuracy: 0.8360\n",
      "Epoch 40/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4160 - accuracy: 0.8429 - val_loss: 0.4213 - val_accuracy: 0.8360\n",
      "Epoch 41/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4083 - accuracy: 0.8491 - val_loss: 0.4153 - val_accuracy: 0.8423\n",
      "Epoch 42/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.8476 - val_loss: 0.4037 - val_accuracy: 0.8707\n",
      "Epoch 43/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3929 - accuracy: 0.8523 - val_loss: 0.3981 - val_accuracy: 0.8644\n",
      "Epoch 44/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3857 - accuracy: 0.8585 - val_loss: 0.3937 - val_accuracy: 0.8486\n",
      "Epoch 45/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3786 - accuracy: 0.8569 - val_loss: 0.3835 - val_accuracy: 0.8738\n",
      "Epoch 46/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3711 - accuracy: 0.8600 - val_loss: 0.3779 - val_accuracy: 0.8707\n",
      "Epoch 47/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3635 - accuracy: 0.8600 - val_loss: 0.3690 - val_accuracy: 0.8833\n",
      "Epoch 48/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3565 - accuracy: 0.8647 - val_loss: 0.3620 - val_accuracy: 0.8833\n",
      "Epoch 49/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3495 - accuracy: 0.8709 - val_loss: 0.3537 - val_accuracy: 0.8801\n",
      "Epoch 50/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3426 - accuracy: 0.8740 - val_loss: 0.3488 - val_accuracy: 0.8864\n",
      "Epoch 51/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3358 - accuracy: 0.8849 - val_loss: 0.3416 - val_accuracy: 0.8896\n",
      "Epoch 52/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8896 - val_loss: 0.3347 - val_accuracy: 0.8927\n",
      "Epoch 53/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3231 - accuracy: 0.8896 - val_loss: 0.3255 - val_accuracy: 0.8927\n",
      "Epoch 54/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3163 - accuracy: 0.8989 - val_loss: 0.3201 - val_accuracy: 0.8991\n",
      "Epoch 55/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3099 - accuracy: 0.9051 - val_loss: 0.3136 - val_accuracy: 0.8991\n",
      "Epoch 56/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3040 - accuracy: 0.9067 - val_loss: 0.3079 - val_accuracy: 0.8991\n",
      "Epoch 57/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2974 - accuracy: 0.9098 - val_loss: 0.3009 - val_accuracy: 0.8991\n",
      "Epoch 58/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2916 - accuracy: 0.9098 - val_loss: 0.2967 - val_accuracy: 0.8991\n",
      "Epoch 59/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2854 - accuracy: 0.9253 - val_loss: 0.2887 - val_accuracy: 0.9085\n",
      "Epoch 60/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2797 - accuracy: 0.9253 - val_loss: 0.2825 - val_accuracy: 0.9117\n",
      "Epoch 61/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2742 - accuracy: 0.9253 - val_loss: 0.2769 - val_accuracy: 0.9148\n",
      "Epoch 62/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2690 - accuracy: 0.9300 - val_loss: 0.2695 - val_accuracy: 0.9243\n",
      "Epoch 63/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2631 - accuracy: 0.9347 - val_loss: 0.2648 - val_accuracy: 0.9274\n",
      "Epoch 64/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2583 - accuracy: 0.9316 - val_loss: 0.2580 - val_accuracy: 0.9338\n",
      "Epoch 65/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2524 - accuracy: 0.9393 - val_loss: 0.2544 - val_accuracy: 0.9274\n",
      "Epoch 66/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2469 - accuracy: 0.9347 - val_loss: 0.2466 - val_accuracy: 0.9369\n",
      "Epoch 67/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2419 - accuracy: 0.9425 - val_loss: 0.2442 - val_accuracy: 0.9369\n",
      "Epoch 68/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2367 - accuracy: 0.9440 - val_loss: 0.2373 - val_accuracy: 0.9369\n",
      "Epoch 69/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2320 - accuracy: 0.9440 - val_loss: 0.2335 - val_accuracy: 0.9401\n",
      "Epoch 70/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2275 - accuracy: 0.9471 - val_loss: 0.2290 - val_accuracy: 0.9401\n",
      "Epoch 71/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2233 - accuracy: 0.9487 - val_loss: 0.2208 - val_accuracy: 0.9432\n",
      "Epoch 72/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2188 - accuracy: 0.9487 - val_loss: 0.2168 - val_accuracy: 0.9432\n",
      "Epoch 73/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2140 - accuracy: 0.9518 - val_loss: 0.2122 - val_accuracy: 0.9432\n",
      "Epoch 74/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2098 - accuracy: 0.9518 - val_loss: 0.2097 - val_accuracy: 0.9464\n",
      "Epoch 75/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2060 - accuracy: 0.9533 - val_loss: 0.2034 - val_accuracy: 0.9432\n",
      "Epoch 76/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2014 - accuracy: 0.9549 - val_loss: 0.2002 - val_accuracy: 0.9464\n",
      "Epoch 77/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1979 - accuracy: 0.9565 - val_loss: 0.1941 - val_accuracy: 0.9495\n",
      "Epoch 78/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1946 - accuracy: 0.9565 - val_loss: 0.1912 - val_accuracy: 0.9495\n",
      "Epoch 79/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1898 - accuracy: 0.9518 - val_loss: 0.1852 - val_accuracy: 0.9558\n",
      "Epoch 80/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1863 - accuracy: 0.9518 - val_loss: 0.1850 - val_accuracy: 0.9495\n",
      "Epoch 81/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1834 - accuracy: 0.9580 - val_loss: 0.1795 - val_accuracy: 0.9527\n",
      "Epoch 82/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1796 - accuracy: 0.9565 - val_loss: 0.1758 - val_accuracy: 0.9558\n",
      "Epoch 83/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1760 - accuracy: 0.9596 - val_loss: 0.1720 - val_accuracy: 0.9621\n",
      "Epoch 84/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1728 - accuracy: 0.9580 - val_loss: 0.1692 - val_accuracy: 0.9621\n",
      "Epoch 85/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1695 - accuracy: 0.9549 - val_loss: 0.1642 - val_accuracy: 0.9621\n",
      "Epoch 86/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1662 - accuracy: 0.9549 - val_loss: 0.1603 - val_accuracy: 0.9621\n",
      "Epoch 87/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1634 - accuracy: 0.9611 - val_loss: 0.1583 - val_accuracy: 0.9621\n",
      "Epoch 88/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1604 - accuracy: 0.9627 - val_loss: 0.1549 - val_accuracy: 0.9621\n",
      "Epoch 89/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1581 - accuracy: 0.9642 - val_loss: 0.1538 - val_accuracy: 0.9621\n",
      "Epoch 90/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1546 - accuracy: 0.9580 - val_loss: 0.1480 - val_accuracy: 0.9621\n",
      "Epoch 91/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1519 - accuracy: 0.9596 - val_loss: 0.1465 - val_accuracy: 0.9621\n",
      "Epoch 92/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1494 - accuracy: 0.9658 - val_loss: 0.1419 - val_accuracy: 0.9685\n",
      "Epoch 93/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1467 - accuracy: 0.9611 - val_loss: 0.1422 - val_accuracy: 0.9621\n",
      "Epoch 94/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1453 - accuracy: 0.9642 - val_loss: 0.1360 - val_accuracy: 0.9685\n",
      "Epoch 95/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1417 - accuracy: 0.9673 - val_loss: 0.1339 - val_accuracy: 0.9685\n",
      "Epoch 96/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1392 - accuracy: 0.9658 - val_loss: 0.1305 - val_accuracy: 0.9685\n",
      "Epoch 97/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1383 - accuracy: 0.9658 - val_loss: 0.1289 - val_accuracy: 0.9685\n",
      "Epoch 98/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1354 - accuracy: 0.9673 - val_loss: 0.1245 - val_accuracy: 0.9653\n",
      "Epoch 99/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1326 - accuracy: 0.9673 - val_loss: 0.1231 - val_accuracy: 0.9653\n",
      "Epoch 100/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1304 - accuracy: 0.9673 - val_loss: 0.1202 - val_accuracy: 0.9653\n",
      "(['relu', 'sigmoid', 'softmax', 'softplus', 'softsign', 'tanh'], [0.9621450901031494, 0.85173499584198, 0.9274448156356812, 0.9495267868041992, 0.9716088175773621, 0.9684542417526245])\n",
      "Epoch 1/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7203 - accuracy: 0.4075 - val_loss: 0.7182 - val_accuracy: 0.3817\n",
      "Epoch 2/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6987 - accuracy: 0.4899 - val_loss: 0.7087 - val_accuracy: 0.4858\n",
      "Epoch 3/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5708 - val_loss: 0.7035 - val_accuracy: 0.5016\n",
      "Epoch 4/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6803 - accuracy: 0.5816 - val_loss: 0.6989 - val_accuracy: 0.5205\n",
      "Epoch 5/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6746 - accuracy: 0.5832 - val_loss: 0.6941 - val_accuracy: 0.5205\n",
      "Epoch 6/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6692 - accuracy: 0.5848 - val_loss: 0.6887 - val_accuracy: 0.5237\n",
      "Epoch 7/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6643 - accuracy: 0.5863 - val_loss: 0.6833 - val_accuracy: 0.5268\n",
      "Epoch 8/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6594 - accuracy: 0.5972 - val_loss: 0.6779 - val_accuracy: 0.5331\n",
      "Epoch 9/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6545 - accuracy: 0.6034 - val_loss: 0.6735 - val_accuracy: 0.5615\n",
      "Epoch 10/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6494 - accuracy: 0.6143 - val_loss: 0.6684 - val_accuracy: 0.5773\n",
      "Epoch 11/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6444 - accuracy: 0.6314 - val_loss: 0.6636 - val_accuracy: 0.5899\n",
      "Epoch 12/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6392 - accuracy: 0.6470 - val_loss: 0.6579 - val_accuracy: 0.5868\n",
      "Epoch 13/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6340 - accuracy: 0.6501 - val_loss: 0.6528 - val_accuracy: 0.5962\n",
      "Epoch 14/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6290 - accuracy: 0.6563 - val_loss: 0.6475 - val_accuracy: 0.5994\n",
      "Epoch 15/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6228 - accuracy: 0.6610 - val_loss: 0.6417 - val_accuracy: 0.6151\n",
      "Epoch 16/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6170 - accuracy: 0.6703 - val_loss: 0.6356 - val_accuracy: 0.6341\n",
      "Epoch 17/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6106 - accuracy: 0.6796 - val_loss: 0.6289 - val_accuracy: 0.6404\n",
      "Epoch 18/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6043 - accuracy: 0.6890 - val_loss: 0.6228 - val_accuracy: 0.6688\n",
      "Epoch 19/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5980 - accuracy: 0.7092 - val_loss: 0.6160 - val_accuracy: 0.6782\n",
      "Epoch 20/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5915 - accuracy: 0.7092 - val_loss: 0.6102 - val_accuracy: 0.6782\n",
      "Epoch 21/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5851 - accuracy: 0.7154 - val_loss: 0.6028 - val_accuracy: 0.6719\n",
      "Epoch 22/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5784 - accuracy: 0.7170 - val_loss: 0.5968 - val_accuracy: 0.6782\n",
      "Epoch 23/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5717 - accuracy: 0.7263 - val_loss: 0.5897 - val_accuracy: 0.6814\n",
      "Epoch 24/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5645 - accuracy: 0.7325 - val_loss: 0.5826 - val_accuracy: 0.6909\n",
      "Epoch 25/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5574 - accuracy: 0.7403 - val_loss: 0.5753 - val_accuracy: 0.6940\n",
      "Epoch 26/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5509 - accuracy: 0.7512 - val_loss: 0.5673 - val_accuracy: 0.7035\n",
      "Epoch 27/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5436 - accuracy: 0.7636 - val_loss: 0.5599 - val_accuracy: 0.7098\n",
      "Epoch 28/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5359 - accuracy: 0.7760 - val_loss: 0.5524 - val_accuracy: 0.7098\n",
      "Epoch 29/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5289 - accuracy: 0.7745 - val_loss: 0.5447 - val_accuracy: 0.7161\n",
      "Epoch 30/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5209 - accuracy: 0.7869 - val_loss: 0.5370 - val_accuracy: 0.7161\n",
      "Epoch 31/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5133 - accuracy: 0.7947 - val_loss: 0.5288 - val_accuracy: 0.7161\n",
      "Epoch 32/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5054 - accuracy: 0.8009 - val_loss: 0.5209 - val_accuracy: 0.7382\n",
      "Epoch 33/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4983 - accuracy: 0.7963 - val_loss: 0.5106 - val_accuracy: 0.7319\n",
      "Epoch 34/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4897 - accuracy: 0.8056 - val_loss: 0.5051 - val_accuracy: 0.7508\n",
      "Epoch 35/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4821 - accuracy: 0.8056 - val_loss: 0.4948 - val_accuracy: 0.7476\n",
      "Epoch 36/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4743 - accuracy: 0.8118 - val_loss: 0.4858 - val_accuracy: 0.7508\n",
      "Epoch 37/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4662 - accuracy: 0.8165 - val_loss: 0.4779 - val_accuracy: 0.7571\n",
      "Epoch 38/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4586 - accuracy: 0.8134 - val_loss: 0.4690 - val_accuracy: 0.7666\n",
      "Epoch 39/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4504 - accuracy: 0.8196 - val_loss: 0.4592 - val_accuracy: 0.7823\n",
      "Epoch 40/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4426 - accuracy: 0.8289 - val_loss: 0.4520 - val_accuracy: 0.7981\n",
      "Epoch 41/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4349 - accuracy: 0.8274 - val_loss: 0.4453 - val_accuracy: 0.8076\n",
      "Epoch 42/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4270 - accuracy: 0.8289 - val_loss: 0.4339 - val_accuracy: 0.8170\n",
      "Epoch 43/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4185 - accuracy: 0.8336 - val_loss: 0.4240 - val_accuracy: 0.8265\n",
      "Epoch 44/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4103 - accuracy: 0.8383 - val_loss: 0.4170 - val_accuracy: 0.8297\n",
      "Epoch 45/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4020 - accuracy: 0.8367 - val_loss: 0.4076 - val_accuracy: 0.8391\n",
      "Epoch 46/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3951 - accuracy: 0.8429 - val_loss: 0.3978 - val_accuracy: 0.8612\n",
      "Epoch 47/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3858 - accuracy: 0.8476 - val_loss: 0.3894 - val_accuracy: 0.8675\n",
      "Epoch 48/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3777 - accuracy: 0.8554 - val_loss: 0.3814 - val_accuracy: 0.8707\n",
      "Epoch 49/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3696 - accuracy: 0.8585 - val_loss: 0.3747 - val_accuracy: 0.8738\n",
      "Epoch 50/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3618 - accuracy: 0.8585 - val_loss: 0.3654 - val_accuracy: 0.8801\n",
      "Epoch 51/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3539 - accuracy: 0.8647 - val_loss: 0.3572 - val_accuracy: 0.8801\n",
      "Epoch 52/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3461 - accuracy: 0.8678 - val_loss: 0.3485 - val_accuracy: 0.8833\n",
      "Epoch 53/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3387 - accuracy: 0.8802 - val_loss: 0.3429 - val_accuracy: 0.8801\n",
      "Epoch 54/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8865 - val_loss: 0.3329 - val_accuracy: 0.8896\n",
      "Epoch 55/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3233 - accuracy: 0.8911 - val_loss: 0.3267 - val_accuracy: 0.8927\n",
      "Epoch 56/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3162 - accuracy: 0.8958 - val_loss: 0.3153 - val_accuracy: 0.8991\n",
      "Epoch 57/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3093 - accuracy: 0.9082 - val_loss: 0.3086 - val_accuracy: 0.9022\n",
      "Epoch 58/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3019 - accuracy: 0.9098 - val_loss: 0.2990 - val_accuracy: 0.9117\n",
      "Epoch 59/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2959 - accuracy: 0.9176 - val_loss: 0.2948 - val_accuracy: 0.9054\n",
      "Epoch 60/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2882 - accuracy: 0.9238 - val_loss: 0.2874 - val_accuracy: 0.9148\n",
      "Epoch 61/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2816 - accuracy: 0.9285 - val_loss: 0.2839 - val_accuracy: 0.9148\n",
      "Epoch 62/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2750 - accuracy: 0.9331 - val_loss: 0.2726 - val_accuracy: 0.9243\n",
      "Epoch 63/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2691 - accuracy: 0.9347 - val_loss: 0.2669 - val_accuracy: 0.9338\n",
      "Epoch 64/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2626 - accuracy: 0.9347 - val_loss: 0.2673 - val_accuracy: 0.9211\n",
      "Epoch 65/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2579 - accuracy: 0.9362 - val_loss: 0.2535 - val_accuracy: 0.9401\n",
      "Epoch 66/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2508 - accuracy: 0.9378 - val_loss: 0.2501 - val_accuracy: 0.9369\n",
      "Epoch 67/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2455 - accuracy: 0.9425 - val_loss: 0.2429 - val_accuracy: 0.9401\n",
      "Epoch 68/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2404 - accuracy: 0.9425 - val_loss: 0.2368 - val_accuracy: 0.9401\n",
      "Epoch 69/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2351 - accuracy: 0.9440 - val_loss: 0.2335 - val_accuracy: 0.9401\n",
      "Epoch 70/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2298 - accuracy: 0.9440 - val_loss: 0.2276 - val_accuracy: 0.9432\n",
      "Epoch 71/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2246 - accuracy: 0.9487 - val_loss: 0.2231 - val_accuracy: 0.9432\n",
      "Epoch 72/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2201 - accuracy: 0.9518 - val_loss: 0.2159 - val_accuracy: 0.9464\n",
      "Epoch 73/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2153 - accuracy: 0.9518 - val_loss: 0.2117 - val_accuracy: 0.9464\n",
      "Epoch 74/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2110 - accuracy: 0.9533 - val_loss: 0.2077 - val_accuracy: 0.9464\n",
      "Epoch 75/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2066 - accuracy: 0.9549 - val_loss: 0.2039 - val_accuracy: 0.9495\n",
      "Epoch 76/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2031 - accuracy: 0.9549 - val_loss: 0.1990 - val_accuracy: 0.9495\n",
      "Epoch 77/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1987 - accuracy: 0.9565 - val_loss: 0.1914 - val_accuracy: 0.9495\n",
      "Epoch 78/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1953 - accuracy: 0.9502 - val_loss: 0.1893 - val_accuracy: 0.9558\n",
      "Epoch 79/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1910 - accuracy: 0.9533 - val_loss: 0.1853 - val_accuracy: 0.9558\n",
      "Epoch 80/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1871 - accuracy: 0.9580 - val_loss: 0.1812 - val_accuracy: 0.9558\n",
      "Epoch 81/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.9518 - val_loss: 0.1802 - val_accuracy: 0.9558\n",
      "Epoch 82/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1804 - accuracy: 0.9502 - val_loss: 0.1747 - val_accuracy: 0.9558\n",
      "Epoch 83/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1768 - accuracy: 0.9580 - val_loss: 0.1704 - val_accuracy: 0.9558\n",
      "Epoch 84/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1738 - accuracy: 0.9533 - val_loss: 0.1681 - val_accuracy: 0.9621\n",
      "Epoch 85/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1703 - accuracy: 0.9565 - val_loss: 0.1622 - val_accuracy: 0.9621\n",
      "Epoch 86/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1677 - accuracy: 0.9549 - val_loss: 0.1615 - val_accuracy: 0.9653\n",
      "Epoch 87/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1640 - accuracy: 0.9596 - val_loss: 0.1553 - val_accuracy: 0.9621\n",
      "Epoch 88/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1618 - accuracy: 0.9596 - val_loss: 0.1550 - val_accuracy: 0.9653\n",
      "Epoch 89/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1584 - accuracy: 0.9565 - val_loss: 0.1492 - val_accuracy: 0.9653\n",
      "Epoch 90/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1558 - accuracy: 0.9580 - val_loss: 0.1462 - val_accuracy: 0.9653\n",
      "Epoch 91/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1532 - accuracy: 0.9596 - val_loss: 0.1439 - val_accuracy: 0.9653\n",
      "Epoch 92/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1505 - accuracy: 0.9580 - val_loss: 0.1441 - val_accuracy: 0.9653\n",
      "Epoch 93/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1479 - accuracy: 0.9611 - val_loss: 0.1397 - val_accuracy: 0.9653\n",
      "Epoch 94/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1457 - accuracy: 0.9627 - val_loss: 0.1355 - val_accuracy: 0.9653\n",
      "Epoch 95/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1429 - accuracy: 0.9642 - val_loss: 0.1347 - val_accuracy: 0.9653\n",
      "Epoch 96/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1409 - accuracy: 0.9627 - val_loss: 0.1307 - val_accuracy: 0.9653\n",
      "Epoch 97/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1387 - accuracy: 0.9658 - val_loss: 0.1284 - val_accuracy: 0.9685\n",
      "Epoch 98/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1366 - accuracy: 0.9627 - val_loss: 0.1283 - val_accuracy: 0.9653\n",
      "Epoch 99/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1342 - accuracy: 0.9658 - val_loss: 0.1257 - val_accuracy: 0.9653\n",
      "Epoch 100/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1327 - accuracy: 0.9673 - val_loss: 0.1220 - val_accuracy: 0.9685\n",
      "(['relu', 'sigmoid', 'softmax', 'softplus', 'softsign', 'tanh', 'selu'], [0.9621450901031494, 0.85173499584198, 0.9274448156356812, 0.9495267868041992, 0.9716088175773621, 0.9684542417526245, 0.9684542417526245])\n",
      "Epoch 1/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9295 - accuracy: 0.4339 - val_loss: 0.7747 - val_accuracy: 0.4763\n",
      "Epoch 2/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7693 - accuracy: 0.4370 - val_loss: 0.6868 - val_accuracy: 0.5016\n",
      "Epoch 3/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.5334 - val_loss: 0.6523 - val_accuracy: 0.6498\n",
      "Epoch 4/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6622 - accuracy: 0.5521 - val_loss: 0.6422 - val_accuracy: 0.5899\n",
      "Epoch 5/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6489 - accuracy: 0.5941 - val_loss: 0.6379 - val_accuracy: 0.5868\n",
      "Epoch 6/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6413 - accuracy: 0.6019 - val_loss: 0.6334 - val_accuracy: 0.5868\n",
      "Epoch 7/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6350 - accuracy: 0.6065 - val_loss: 0.6277 - val_accuracy: 0.5931\n",
      "Epoch 8/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6284 - accuracy: 0.6252 - val_loss: 0.6227 - val_accuracy: 0.6151\n",
      "Epoch 9/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6218 - accuracy: 0.6330 - val_loss: 0.6150 - val_accuracy: 0.6183\n",
      "Epoch 10/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6145 - accuracy: 0.6299 - val_loss: 0.6079 - val_accuracy: 0.6215\n",
      "Epoch 11/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6067 - accuracy: 0.6547 - val_loss: 0.6004 - val_accuracy: 0.6246\n",
      "Epoch 12/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5983 - accuracy: 0.6454 - val_loss: 0.5921 - val_accuracy: 0.6341\n",
      "Epoch 13/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5914 - accuracy: 0.6672 - val_loss: 0.5815 - val_accuracy: 0.6498\n",
      "Epoch 14/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5813 - accuracy: 0.6610 - val_loss: 0.5736 - val_accuracy: 0.6562\n",
      "Epoch 15/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5705 - accuracy: 0.6656 - val_loss: 0.5639 - val_accuracy: 0.6593\n",
      "Epoch 16/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5598 - accuracy: 0.6781 - val_loss: 0.5526 - val_accuracy: 0.6751\n",
      "Epoch 17/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5487 - accuracy: 0.6858 - val_loss: 0.5423 - val_accuracy: 0.6719\n",
      "Epoch 18/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5365 - accuracy: 0.6921 - val_loss: 0.5308 - val_accuracy: 0.6751\n",
      "Epoch 19/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5236 - accuracy: 0.7076 - val_loss: 0.5160 - val_accuracy: 0.6814\n",
      "Epoch 20/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5099 - accuracy: 0.7263 - val_loss: 0.5033 - val_accuracy: 0.6814\n",
      "Epoch 21/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4946 - accuracy: 0.7449 - val_loss: 0.4861 - val_accuracy: 0.7129\n",
      "Epoch 22/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4790 - accuracy: 0.7652 - val_loss: 0.4729 - val_accuracy: 0.7192\n",
      "Epoch 23/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.7729 - val_loss: 0.4557 - val_accuracy: 0.7508\n",
      "Epoch 24/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4449 - accuracy: 0.7978 - val_loss: 0.4379 - val_accuracy: 0.7729\n",
      "Epoch 25/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.8134 - val_loss: 0.4141 - val_accuracy: 0.8486\n",
      "Epoch 26/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4084 - accuracy: 0.8305 - val_loss: 0.3999 - val_accuracy: 0.8265\n",
      "Epoch 27/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3900 - accuracy: 0.8445 - val_loss: 0.3785 - val_accuracy: 0.8612\n",
      "Epoch 28/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3696 - accuracy: 0.8585 - val_loss: 0.3642 - val_accuracy: 0.8580\n",
      "Epoch 29/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3488 - accuracy: 0.8694 - val_loss: 0.3387 - val_accuracy: 0.8896\n",
      "Epoch 30/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8896 - val_loss: 0.3195 - val_accuracy: 0.9054\n",
      "Epoch 31/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3093 - accuracy: 0.8942 - val_loss: 0.3022 - val_accuracy: 0.9117\n",
      "Epoch 32/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2892 - accuracy: 0.9160 - val_loss: 0.2823 - val_accuracy: 0.9180\n",
      "Epoch 33/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2701 - accuracy: 0.9269 - val_loss: 0.2682 - val_accuracy: 0.9148\n",
      "Epoch 34/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2519 - accuracy: 0.9347 - val_loss: 0.2463 - val_accuracy: 0.9243\n",
      "Epoch 35/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2351 - accuracy: 0.9347 - val_loss: 0.2316 - val_accuracy: 0.9274\n",
      "Epoch 36/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2181 - accuracy: 0.9533 - val_loss: 0.2136 - val_accuracy: 0.9464\n",
      "Epoch 37/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.2023 - accuracy: 0.9580 - val_loss: 0.1943 - val_accuracy: 0.9653\n",
      "Epoch 38/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1899 - accuracy: 0.9611 - val_loss: 0.1843 - val_accuracy: 0.9590\n",
      "Epoch 39/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1761 - accuracy: 0.9689 - val_loss: 0.1743 - val_accuracy: 0.9590\n",
      "Epoch 40/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1644 - accuracy: 0.9658 - val_loss: 0.1655 - val_accuracy: 0.9621\n",
      "Epoch 41/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1533 - accuracy: 0.9642 - val_loss: 0.1583 - val_accuracy: 0.9590\n",
      "Epoch 42/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1428 - accuracy: 0.9689 - val_loss: 0.1399 - val_accuracy: 0.9685\n",
      "Epoch 43/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1340 - accuracy: 0.9658 - val_loss: 0.1335 - val_accuracy: 0.9685\n",
      "Epoch 44/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1261 - accuracy: 0.9705 - val_loss: 0.1212 - val_accuracy: 0.9748\n",
      "Epoch 45/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1183 - accuracy: 0.9673 - val_loss: 0.1164 - val_accuracy: 0.9748\n",
      "Epoch 46/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1114 - accuracy: 0.9689 - val_loss: 0.1022 - val_accuracy: 0.9842\n",
      "Epoch 47/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1060 - accuracy: 0.9705 - val_loss: 0.1027 - val_accuracy: 0.9811\n",
      "Epoch 48/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.1006 - accuracy: 0.9767 - val_loss: 0.0892 - val_accuracy: 0.9874\n",
      "Epoch 49/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0971 - accuracy: 0.9689 - val_loss: 0.0882 - val_accuracy: 0.9874\n",
      "Epoch 50/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0915 - accuracy: 0.9705 - val_loss: 0.0826 - val_accuracy: 0.9905\n",
      "Epoch 51/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0874 - accuracy: 0.9720 - val_loss: 0.0879 - val_accuracy: 0.9811\n",
      "Epoch 52/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0851 - accuracy: 0.9736 - val_loss: 0.0781 - val_accuracy: 0.9874\n",
      "Epoch 53/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0810 - accuracy: 0.9736 - val_loss: 0.0729 - val_accuracy: 0.9905\n",
      "Epoch 54/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0782 - accuracy: 0.9689 - val_loss: 0.0681 - val_accuracy: 0.9937\n",
      "Epoch 55/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0770 - accuracy: 0.9751 - val_loss: 0.0650 - val_accuracy: 0.9968\n",
      "Epoch 56/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0736 - accuracy: 0.9751 - val_loss: 0.0661 - val_accuracy: 0.9905\n",
      "Epoch 57/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0711 - accuracy: 0.9798 - val_loss: 0.0590 - val_accuracy: 0.9937\n",
      "Epoch 58/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0691 - accuracy: 0.9751 - val_loss: 0.0646 - val_accuracy: 0.9874\n",
      "Epoch 59/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0669 - accuracy: 0.9798 - val_loss: 0.0527 - val_accuracy: 0.9905\n",
      "Epoch 60/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0666 - accuracy: 0.9751 - val_loss: 0.0574 - val_accuracy: 0.9968\n",
      "Epoch 61/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0647 - accuracy: 0.9736 - val_loss: 0.0570 - val_accuracy: 0.9937\n",
      "Epoch 62/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0634 - accuracy: 0.9798 - val_loss: 0.0500 - val_accuracy: 0.9968\n",
      "Epoch 63/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0610 - accuracy: 0.9751 - val_loss: 0.0550 - val_accuracy: 0.9905\n",
      "Epoch 64/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0603 - accuracy: 0.9767 - val_loss: 0.0578 - val_accuracy: 0.9874\n",
      "Epoch 65/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0600 - accuracy: 0.9813 - val_loss: 0.0472 - val_accuracy: 0.9968\n",
      "Epoch 66/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0573 - accuracy: 0.9782 - val_loss: 0.0496 - val_accuracy: 0.9968\n",
      "Epoch 67/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0562 - accuracy: 0.9798 - val_loss: 0.0457 - val_accuracy: 0.9968\n",
      "Epoch 68/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0555 - accuracy: 0.9891 - val_loss: 0.0391 - val_accuracy: 0.9905\n",
      "Epoch 69/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0544 - accuracy: 0.9751 - val_loss: 0.0451 - val_accuracy: 0.9968\n",
      "Epoch 70/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0532 - accuracy: 0.9813 - val_loss: 0.0430 - val_accuracy: 0.9968\n",
      "Epoch 71/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0526 - accuracy: 0.9829 - val_loss: 0.0393 - val_accuracy: 0.9968\n",
      "Epoch 72/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0510 - accuracy: 0.9829 - val_loss: 0.0390 - val_accuracy: 0.9968\n",
      "Epoch 73/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0502 - accuracy: 0.9798 - val_loss: 0.0473 - val_accuracy: 0.9937\n",
      "Epoch 74/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0510 - accuracy: 0.9813 - val_loss: 0.0469 - val_accuracy: 0.9937\n",
      "Epoch 75/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0493 - accuracy: 0.9798 - val_loss: 0.0373 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0479 - accuracy: 0.9798 - val_loss: 0.0387 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0468 - accuracy: 0.9813 - val_loss: 0.0459 - val_accuracy: 0.9937\n",
      "Epoch 78/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0482 - accuracy: 0.9844 - val_loss: 0.0396 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0463 - accuracy: 0.9891 - val_loss: 0.0347 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0454 - accuracy: 0.9798 - val_loss: 0.0346 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0446 - accuracy: 0.9876 - val_loss: 0.0362 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0440 - accuracy: 0.9876 - val_loss: 0.0359 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0429 - accuracy: 0.9876 - val_loss: 0.0333 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0426 - accuracy: 0.9844 - val_loss: 0.0327 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0427 - accuracy: 0.9860 - val_loss: 0.0310 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0411 - accuracy: 0.9876 - val_loss: 0.0299 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0418 - accuracy: 0.9860 - val_loss: 0.0385 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0408 - accuracy: 0.9860 - val_loss: 0.0381 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0393 - accuracy: 0.9907 - val_loss: 0.0296 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0392 - accuracy: 0.9844 - val_loss: 0.0356 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0391 - accuracy: 0.9844 - val_loss: 0.0320 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0383 - accuracy: 0.9907 - val_loss: 0.0259 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0369 - accuracy: 0.9860 - val_loss: 0.0323 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0375 - accuracy: 0.9876 - val_loss: 0.0263 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0369 - accuracy: 0.9876 - val_loss: 0.0281 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0383 - accuracy: 0.9860 - val_loss: 0.0236 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0371 - accuracy: 0.9829 - val_loss: 0.0289 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0356 - accuracy: 0.9891 - val_loss: 0.0305 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0348 - accuracy: 0.9876 - val_loss: 0.0316 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.0351 - accuracy: 0.9891 - val_loss: 0.0298 - val_accuracy: 1.0000\n",
      "(['relu', 'sigmoid', 'softmax', 'softplus', 'softsign', 'tanh', 'selu', 'exponential'], [0.9621450901031494, 0.85173499584198, 0.9274448156356812, 0.9495267868041992, 0.9716088175773621, 0.9684542417526245, 0.9684542417526245, 1.0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Creating a loop which will take the max Validation Accuracy score out of all Activation Functions\n",
    "\n",
    "names = []\n",
    "results = []\n",
    "for name, model in models:\n",
    "    history = model.fit(X_train, y_train, validation_split = 0.33, batch_size = 10, epochs = 100)\n",
    "    results.append(max(history.history['val_accuracy']))\n",
    "    names.append(name) \n",
    "    msg = (names, results)\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbdcccac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['relu',\n",
       "  'sigmoid',\n",
       "  'softmax',\n",
       "  'softplus',\n",
       "  'softsign',\n",
       "  'tanh',\n",
       "  'selu',\n",
       "  'exponential'],\n",
       " [0.9621450901031494,\n",
       "  0.85173499584198,\n",
       "  0.9274448156356812,\n",
       "  0.9495267868041992,\n",
       "  0.9716088175773621,\n",
       "  0.9684542417526245,\n",
       "  0.9684542417526245,\n",
       "  1.0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "840c4813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activation Function</th>\n",
       "      <th>Val_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.962145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.851735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>softmax</td>\n",
       "      <td>0.927445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>softplus</td>\n",
       "      <td>0.949527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>softsign</td>\n",
       "      <td>0.971609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.968454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>selu</td>\n",
       "      <td>0.968454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>exponential</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Activation Function Val_Accuracy\n",
       "0                relu     0.962145\n",
       "1             sigmoid     0.851735\n",
       "2             softmax     0.927445\n",
       "3            softplus     0.949527\n",
       "4            softsign     0.971609\n",
       "5                tanh     0.968454\n",
       "6                selu     0.968454\n",
       "7         exponential          1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame of performance of each activation function\n",
    "\n",
    "frame = pd.DataFrame(msg).T\n",
    "frame.columns = ['Activation Function', 'Val_Accuracy']\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4f86761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activation Function</th>\n",
       "      <th>Val_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>exponential</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Activation Function Val_Accuracy\n",
       "7         exponential          1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check which activation function is performing best\n",
    "\n",
    "frame[frame.Val_Accuracy == frame.Val_Accuracy.max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b1be66",
   "metadata": {},
   "source": [
    "## Plots to see the trend of Accuracy and Loss against number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4098e193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# summarize history for accuracy\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc = 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e9cb451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40370f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aab58dc",
   "metadata": {},
   "source": [
    "## Confusion Matrix and Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c19392b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "\n",
      " [[231   1]\n",
      " [  0 180]]\n",
      "\n",
      " Accuracy Score: 0.9975728155339806\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "print('Confusion Matrix: \\n\\n', confusion_matrix(y_test, y_pred))\n",
    "print('\\n Accuracy Score:', accuracy_score(y_pred, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
